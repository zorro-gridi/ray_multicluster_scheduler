#!/usr/bin/env python3
"""
æµ‹è¯• Task é˜Ÿåˆ—å¤„ç†å’Œå¹¶å‘ä¿®å¤
éªŒè¯ is_processing æ ‡è®°é˜²æ­¢ä»»åŠ¡é‡å¤æ‰§è¡Œ
"""

import time
import sys
import os
import threading
from unittest.mock import Mock, patch, MagicMock
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ray_multicluster_scheduler.common.model import TaskDescription, ResourceSnapshot
from ray_multicluster_scheduler.scheduler.lifecycle.task_lifecycle_manager import TaskLifecycleManager
from ray_multicluster_scheduler.app.client_api.submit_task import submit_task, get_task_status

def test_single_task_concurrent_protection():
    """æµ‹è¯• 1.1: å•ä¸ªä»»åŠ¡å¹¶å‘æ‰§è¡Œä¿æŠ¤"""
    print("\n=== æµ‹è¯• 1.1: å•ä¸ªä»»åŠ¡å¹¶å‘æ‰§è¡Œä¿æŠ¤ ===")

    # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
    def test_func():
        return "task_result"

    task_desc = TaskDescription(
        task_id="test_concurrent_task",
        func_or_class=test_func,
        args=(),
        kwargs={},
        is_actor=False,
        is_top_level_task=False,
        is_processing=False  # åˆå§‹ä¸º False
    )

    # æ¨¡æ‹Ÿä¸¤ä¸ªå¹¶å‘çº¿ç¨‹åŒæ—¶å°è¯•å¤„ç†åŒä¸€ä»»åŠ¡
    processing_count = [0]
    skipped_count = [0]

    def mock_process_task(task):
        # æ¨¡æ‹Ÿ _process_task å¼€å§‹æ—¶çš„æ£€æŸ¥
        if task.is_processing:
            print(f"âœ“ ä»»åŠ¡ {task.task_id} å·²åœ¨å¤„ç†ä¸­ï¼Œè·³è¿‡é‡å¤æ‰§è¡Œï¼ˆå¹¶å‘ä¿æŠ¤ç”Ÿæ•ˆï¼‰")
            skipped_count.append(1)  # ä¿®å¤ï¼šä½¿ç”¨ append æ›¿ä»£ += 1
            return False

        # æ¨¡æ‹Ÿè®¾ç½® is_processing
        task.is_processing = True
        processing_count[0] += 1

        # æ¨¡æ‹Ÿæ‰§è¡Œ
        time.sleep(0.1)

        # ä¿®å¤ï¼šæ¨¡æ‹Ÿ finally å—ï¼Œç¡®ä¿æ ‡è®°è¢«é‡ç½®
        task.is_processing = False
        return True

    # åˆ›å»ºä¸¤ä¸ªå¹¶å‘çº¿ç¨‹
    t1 = threading.Thread(target=lambda: mock_process_task(task_desc))
    t2 = threading.Thread(target=lambda: mock_process_task(task_desc))

    t1.start()
    t2.start()

    t1.join()
    t2.join()

    # éªŒè¯ï¼šåªæœ‰ä¸€ä¸ªæˆåŠŸæ‰§è¡Œï¼Œå¦ä¸€ä¸ªè¢«è·³è¿‡
    assert processing_count[0] == 1, f"âœ— é¢„æœŸå¤„ç†1æ¬¡ï¼Œå®é™…å¤„ç†{processing_count[0]}æ¬¡"
    assert len(skipped_count) == 1, f"âœ— é¢„æœŸè·³è¿‡1æ¬¡ï¼Œå®é™…è·³è¿‡{len(skipped_count)}æ¬¡"
    assert task_desc.is_processing == False, "âœ— ä»»åŠ¡æœªé‡ç½®ä¸º False"

    print("âœ“ å¹¶å‘ä¿æŠ¤ç”Ÿæ•ˆï¼šä»»åŠ¡åªæ‰§è¡Œä¸€æ¬¡ï¼Œé‡å¤æ‰§è¡Œè¢«é˜»æ­¢")
    return True


def test_multiple_tasks_concurrent_protection():
    """æµ‹è¯• 1.2: å¤šä¸ªä»»åŠ¡å¹¶å‘å¤„ç†ä¿æŠ¤"""
    print("\n=== æµ‹è¯• 1.2: å¤šä¸ªä»»åŠ¡å¹¶å‘å¤„ç†ä¿æŠ¤ ===")

    results = []

    def process_single_task(task_id):
        """æ¨¡æ‹Ÿå¤„ç†å•ä¸ªä»»åŠ¡"""
        task = TaskDescription(
            task_id=task_id,
            func_or_class=lambda: f"result_{task_id}",
            is_actor=False,
            is_processing=False
        )

        # æ¨¡æ‹Ÿ _process_task çš„å¹¶å‘æ£€æŸ¥
        if task.is_processing:
            results.append(f"skipped_{task_id}")
            return

        task.is_processing = True
        time.sleep(0.05)
        results.append(f"processed_{task_id}")
        task.is_processing = False

    # åˆ›å»ºå¤šä¸ªä»»åŠ¡å¹¶å¹¶å‘å¤„ç†
    tasks = ["task_A", "task_B", "task_C"]
    threads = []
    for task_id in tasks:
        t = threading.Thread(target=lambda tid=task_id: process_single_task(tid))
        t.start()
        threads.append(t)

    for t in threads:
        t.join()

    # éªŒè¯ï¼šæ¯ä¸ªä»»åŠ¡éƒ½è¢«å¤„ç†
    processed = [r for r in results if r.startswith("processed_")]
    skipped = [r for r in results if r.startswith("skipped_")]

    assert len(processed) == 3, f"âœ— é¢„æœŸå¤„ç†3ä¸ªä»»åŠ¡ï¼Œå®é™…{len(processed)}ä¸ª"
    assert len(skipped) == 0, f"âœ— é¢„æœŸè·³è¿‡0ä¸ªï¼Œå®é™…{len(skipped)}ä¸ª"

    print(f"âœ“ æ‰€æœ‰ {len(processed)} ä¸ªä»»åŠ¡éƒ½æ­£ç¡®å¤„ç†ï¼Œæ²¡æœ‰å¹¶å‘å†²çª")
    return True


def test_task_queue_mechanism():
    """æµ‹è¯• 2.1: ä»»åŠ¡è¿›å…¥é˜Ÿåˆ—æœºåˆ¶"""
    print("\n=== æµ‹è¯• 2.1: ä»»åŠ¡è¿›å…¥é˜Ÿåˆ—æœºåˆ¶ ===")

    try:
        # æ¨¡æ‹Ÿæ‰€æœ‰é›†ç¾¤èµ„æºè¶…è¿‡é˜ˆå€¼
        with patch('ray_multicluster_scheduler.scheduler.lifecycle.task_lifecycle_manager.ClusterMonitor') as MockMonitor:
            mock_monitor = MockMonitor.return_value
            mock_monitor.get_all_cluster_info.return_value = {
                'cluster1': {
                    'metadata': Mock(),
                    'snapshot': ResourceSnapshot(
                        cluster_name='cluster1',
                        cluster_cpu_usage_percent=80.0,  # è¶…è¿‡é˜ˆå€¼
                        cluster_mem_usage_percent=85.0,
                        cluster_cpu_used_cores=8.0,
                        cluster_cpu_total_cores=10.0,
                        cluster_mem_used_mb=8500,
                        cluster_mem_total_mb=10000
                    )
                },
                'cluster2': {
                    'metadata': Mock(),
                    'snapshot': ResourceSnapshot(
                        cluster_name='cluster2',
                        cluster_cpu_usage_percent=85.0,  # è¶…è¿‡é˜ˆå€¼
                        cluster_mem_usage_percent=90.0,
                        cluster_cpu_used_cores=8.5,
                        cluster_cpu_total_cores=10.0,
                        cluster_mem_used_mb=9000,
                        cluster_mem_total_mb=10000
                    )
                }
            }

            # æäº¤ä»»åŠ¡ï¼ˆåº”è¯¥è¿›å…¥é˜Ÿåˆ—ï¼‰
            def sample_task():
                return "result"

            task_id, result = submit_task(
                func=sample_task,
                args=(),
                preferred_cluster=None
            )

            print(f"ä»»åŠ¡å·²æäº¤ï¼Œtask_id: {task_id}, result: {result}")

            # éªŒè¯ï¼šresult æ˜¯ task_idï¼ˆè¡¨ç¤ºæ’é˜Ÿï¼‰
            assert result == task_id, "âœ— é¢„æœŸä»»åŠ¡è¿›å…¥é˜Ÿåˆ—ï¼Œè¿”å› task_id"

            # ç­‰å¾…ä¸€ä¸‹è®©è°ƒåº¦å™¨å¤„ç†
            time.sleep(0.5)

            # éªŒè¯ï¼šä»»åŠ¡çŠ¶æ€ä¸º QUEUED
            status = get_task_status(task_id)
            print(f"ä»»åŠ¡ {task_id} å½“å‰çŠ¶æ€: {status}")

            # é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡åº”è¯¥æ˜¾ç¤ºä¸º QUEUED
            assert status == "QUEUED", f"âœ— é¢„æœŸçŠ¶æ€ä¸ºQUEUEDï¼Œå®é™…ä¸º{status}"

            print("âœ“ ä»»åŠ¡æ­£ç¡®è¿›å…¥é˜Ÿåˆ—ï¼ŒçŠ¶æ€ä¸º QUEUED")
            return True

    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_task_dequeue_and_execute():
    """æµ‹è¯• 2.2: ä»é˜Ÿåˆ—å–å‡ºå¹¶æ‰§è¡Œä»»åŠ¡"""
    print("\n=== æµ‹è¯• 2.2: ä»é˜Ÿåˆ—å–å‡ºå¹¶æ‰§è¡Œä»»åŠ¡ ===")

    try:
        # åˆå§‹åŒ–è°ƒåº¦å™¨
        from ray_multicluster_scheduler.app.client_api.unified_scheduler import initialize_scheduler_environment
        task_lifecycle_manager = initialize_scheduler_environment()

        # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
        def simple_task():
            time.sleep(0.1)
            return "completed"

        task_id, initial_result = submit_task(
            func=simple_task,
            args=(),
            preferred_cluster=None
        )

        print(f"ä»»åŠ¡ {task_id} å·²æäº¤ï¼Œåˆå§‹ç»“æœ: {initial_result}")

        # éªŒè¯ä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­
        if initial_result == task_id:
            print("âœ“ ä»»åŠ¡å·²åœ¨é˜Ÿåˆ—ä¸­")

            # ç­‰å¾…èµ„æºæ¢å¤å¹¶æ‰§è¡Œï¼ˆæœ€å¤š5ç§’ï¼‰
            max_wait = 5
            start = time.time()

            while time.time() - start < max_wait:
                status = get_task_status(task_id)
                print(f"ç­‰å¾…ä¸­... å½“å‰çŠ¶æ€: {status}")

                if status != "QUEUED":
                    # ä»»åŠ¡å·²è¢«æ‰§è¡Œ
                    print(f"âœ“ ä»»åŠ¡ {task_id} å·²ä»é˜Ÿåˆ—å–å‡ºå¹¶æ‰§è¡Œï¼ŒçŠ¶æ€: {status}")
                    return True

                time.sleep(0.5)

            print(f"âš ï¸ ä»»åŠ¡åœ¨ {max_wait} ç§’å†…ä»æœªæ‰§è¡Œ")
            return False
        else:
            # ä»»åŠ¡ç«‹å³æ‰§è¡Œï¼ˆé˜Ÿåˆ—ä¸ºç©ºï¼‰
            print(f"âœ“ ä»»åŠ¡ {task_id} ç«‹å³æ‰§è¡Œ")
            return True

    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_finally_block_exception_clear():
    """æµ‹è¯• 5.1: finally å—å¼‚å¸¸æ—¶æ ‡è®°æ¸…é™¤"""
    print("\n=== æµ‹è¯• 5.1: finally å—å¼‚å¸¸æ—¶æ ‡è®°æ¸…é™¤ ===")

    try:
        # åˆ›å»ºä¸€ä¸ªä»»åŠ¡å¹¶æ¨¡æ‹Ÿå¼‚å¸¸å¤„ç†
        task = TaskDescription(
            task_id="test_finally_task",
            func_or_class=lambda: "result",
            is_actor=False,
            is_processing=False
        )

        # æ¨¡æ‹Ÿ _process_task çš„å¼‚å¸¸å¤„ç†
        exception_raised = False
        processing_reset = False

        def mock_process_with_exception():
            nonlocal exception_raised, processing_reset
            try:
                # æ¨¡æ‹Ÿè®¾ç½® is_processing
                task.is_processing = True
                # æ¨¡æ‹ŸæŠ›å‡ºå¼‚å¸¸
                raise RuntimeError("Simulated exception")
            except RuntimeError:
                exception_raised = True
                raise
            finally:
                # æ¨¡æ‹Ÿ finally å—
                task.is_processing = False
                processing_reset = True

        # æ‰§è¡Œæ¨¡æ‹Ÿ
        try:
            mock_process_with_exception()
        except RuntimeError:
            pass  # é¢„æœŸçš„å¼‚å¸¸

        # éªŒè¯ï¼šå¼‚å¸¸è¢«æŠ›å‡º
        assert exception_raised, "âœ— å¼‚å¸¸æœªæ­£ç¡®æŠ›å‡º"

        # éªŒè¯ï¼šfinally å—æ‰§è¡Œäº†
        assert processing_reset, "âœ— finally å—æœªæ‰§è¡Œ"

        # éªŒè¯ï¼šis_processing è¢«é‡ç½®
        assert task.is_processing == False, "âœ— is_processing æœªè¢«é‡ç½®ä¸º False"

        print("âœ“ finally å—æ­£ç¡®æ‰§è¡Œï¼Œis_processing æ ‡è®°è¢«é‡ç½®")
        return True

    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯• Task é˜Ÿåˆ—å¤„ç†å’Œå¹¶å‘ä¿®å¤...")
    print("=" * 60)

    results = []

    # Test 1.1: å•ä»»åŠ¡å¹¶å‘ä¿æŠ¤
    try:
        results.append(("1.1", test_single_task_concurrent_protection()))
    except AssertionError as e:
        print(f"âœ— æµ‹è¯• 1.1 å¤±è´¥: {e}")
        results.append(("1.1", False))

    # Test 1.2: å¤šä»»åŠ¡å¹¶å‘ä¿æŠ¤
    try:
        results.append(("1.2", test_multiple_tasks_concurrent_protection()))
    except AssertionError as e:
        print(f"âœ— æµ‹è¯• 1.2 å¤±è´¥: {e}")
        results.append(("1.2", False))

    # Test 2.1: ä»»åŠ¡è¿›å…¥é˜Ÿåˆ—æœºåˆ¶
    try:
        results.append(("2.1", test_task_queue_mechanism()))
    except AssertionError as e:
        print(f"âœ— æµ‹è¯• 2.1 å¤±è´¥: {e}")
        results.append(("2.1", False))

    # Test 2.2: ä»é˜Ÿåˆ—å–å‡ºå¹¶æ‰§è¡Œ
    try:
        results.append(("2.2", test_task_dequeue_and_execute()))
    except AssertionError as e:
        print(f"âœ— æµ‹è¯• 2.2 å¤±è´¥: {e}")
        results.append(("2.2", False))

    # Test 5.1: finally å—å¼‚å¸¸æ¸…é™¤
    try:
        results.append(("5.1", test_finally_block_exception_clear()))
    except AssertionError as e:
        print(f"âœ— æµ‹è¯• 5.1 å¤±è´¥: {e}")
        results.append(("5.1", False))

    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»:")
    print("-" * 60)

    total_tests = len(results)
    passed_tests = sum(1 for _, success in results if success)
    failed_tests = total_tests - passed_tests

    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"é€šè¿‡: {passed_tests}")
    print(f"å¤±è´¥: {failed_tests}")
    print(f"æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")

    if passed_tests == total_tests:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Task å¹¶å‘å’Œé˜Ÿåˆ—å¤„ç†ä¿®å¤æœ‰æ•ˆï¼")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
        failed_list = [name for name, success in results if not success]
        print(f"å¤±è´¥çš„æµ‹è¯•: {failed_list}")

    print("=" * 60)
