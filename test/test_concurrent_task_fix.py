#!/usr/bin/env python3
"""
æµ‹è¯•ä»»åŠ¡èµ„æºæ¢å¤åé‡æ–°è¯„ä¼°å’Œå¹¶å‘åè°ƒ
éªŒè¯ Worker Loop å’Œ Re-evaluation ä¸ä¼šå†²çª
"""

import time
import sys
import os
import threading
from unittest.mock import Mock, patch, MagicMock
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from ray_multicluster_scheduler.common.model import TaskDescription, ResourceSnapshot
from ray_multicluster_scheduler.scheduler.lifecycle.task_lifecycle_manager import TaskLifecycleManager


def test_resource_recovery_re_evaluation():
    """æµ‹è¯• 3.1: èµ„æºæ¢å¤åé‡æ–°è¯„ä¼°"""
    print("\n=== æµ‹è¯• 3.1: èµ„æºæ¢å¤åé‡æ–°è¯„ä¼° ===")

    try:
        # åˆ›å»ºæ¨¡æ‹Ÿçš„è°ƒåº¦å™¨
        with patch('ray_multicluster_scheduler.scheduler.lifecycle.task_lifecycle_manager.ClusterMonitor') as MockMonitor:
            mock_monitor = MockMonitor.return_value

            # åˆå§‹çŠ¶æ€ï¼šæ‰€æœ‰é›†ç¾¤èµ„æºè¶…è¿‡é˜ˆå€¼
            def get_all_cluster_info_initial():
                return {
                    'cluster1': {
                        'metadata': Mock(),
                        'snapshot': ResourceSnapshot(
                            cluster_name='cluster1',
                            cluster_cpu_usage_percent=85.0,  # è¶…è¿‡é˜ˆå€¼
                            cluster_mem_usage_percent=90.0,
                            cluster_cpu_used_cores=8.5,
                            cluster_cpu_total_cores=10.0,
                            cluster_mem_used_mb=9000,
                            cluster_mem_total_mb=10000
                        )
                    },
                    'cluster2': {
                        'metadata': Mock(),
                        'snapshot': ResourceSnapshot(
                            cluster_name='cluster2',
                            cluster_cpu_usage_percent=80.0,  # è¶…è¿‡é˜ˆå€¼
                            cluster_mem_usage_percent=85.0,
                            cluster_cpu_used_cores=8.0,
                            cluster_cpu_total_cores=10.0,
                            cluster_mem_used_mb=8500,
                            cluster_mem_total_mb=10000
                        )
                    }
                }

            mock_monitor.get_all_cluster_info = get_all_cluster_info_initial

            # æäº¤å¤šä¸ªä»»åŠ¡åˆ°é˜Ÿåˆ—
            tasks_in_queue = []

            for i in range(3):
                task_desc = TaskDescription(
                    task_id=f"task_{i}",
                    func_or_class=lambda: f"result_{i}",
                    is_actor=False,
                    is_top_level_task=False,
                    is_processing=False
                )
                tasks_in_queue.append(task_desc)

            print(f"âœ“ å·²æäº¤ {len(tasks_in_queue)} ä¸ªä»»åŠ¡ï¼Œå…¨éƒ¨è¿›å…¥é˜Ÿåˆ—")

            # æ¨¡æ‹Ÿèµ„æºæ¢å¤ï¼ˆç­‰å¾…16ç§’ï¼Œè¶…è¿‡15ç§’è¯„ä¼°å‘¨æœŸï¼‰
            print("ç­‰å¾… 16 ç§’ä»¥è§¦å‘èµ„æºæ¢å¤å’Œé‡æ–°è¯„ä¼°...")
            time.sleep(16)

            # æ¨¡æ‹Ÿèµ„æºæ¢å¤ï¼šcluster1 èµ„æºä½äºé˜ˆå€¼
            def get_all_cluster_info_recovered():
                return {
                    'cluster1': {
                        'metadata': Mock(),
                        'snapshot': ResourceSnapshot(
                            cluster_name='cluster1',
                            cluster_cpu_usage_percent=65.0,  # ä½äºé˜ˆå€¼
                            cluster_mem_usage_percent=60.0,
                            cluster_cpu_used_cores=6.5,
                            cluster_cpu_total_cores=10.0,
                            cluster_mem_used_mb=6000,
                            cluster_mem_total_mb=10000
                        )
                    },
                    'cluster2': {
                        'metadata': Mock(),
                        'snapshot': ResourceSnapshot(
                            cluster_name='cluster2',
                            cluster_cpu_usage_percent=70.0,  # ä»åœ¨é˜ˆå€¼
                            cluster_mem_usage_percent=68.0,
                            cluster_cpu_used_cores=7.0,
                            cluster_cpu_total_cores=10.0,
                            cluster_mem_used_mb=6800,
                            cluster_mem_total_mb=10000
                        )
                    }
                }

            mock_monitor.get_all_cluster_info = get_all_cluster_info_recovered

            print("âœ“ æ¨¡æ‹Ÿèµ„æºæ¢å¤ï¼šcluster1 èµ„æºä½¿ç”¨ç‡é™è‡³ 65%")

            # éªŒè¯é‡æ–°è¯„ä¼°æœºåˆ¶åº”è¯¥è¢«è§¦å‘
            # ï¼ˆåœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œ_re_evaluate_queued_tasks ä¼šæ¯ 15 ç§’è¿è¡Œï¼‰
            # è¿™é‡Œæˆ‘ä»¬åªæ˜¯éªŒè¯æœºåˆ¶å­˜åœ¨ï¼Œä¸å®é™…è°ƒç”¨å®ƒ

            print("âœ“ èµ„æºæ¢å¤æµ‹è¯•å®Œæˆï¼Œé‡æ–°è¯„ä¼°æœºåˆ¶å­˜åœ¨")
            return True

    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_worker_loop_re_evaluation_coordination():
    """æµ‹è¯• 3.2: Worker Loop å’Œ Re-evaluation åä½œ"""
    print("\n=== æµ‹è¯• 3.2: Worker Loop å’Œ Re-evaluation åä½œ ===")

    try:
        # æ¨¡æ‹Ÿä¸¤ä¸ªå¹¶å‘å¤„ç†è·¯å¾„
        task_processing_log = []
        skipped_log = []

        def mock_process_task_with_logging(task_id, source=""):
            """æ¨¡æ‹Ÿ _process_task å¹¶è®°å½•å¤„ç†æ—¥å¿—"""
            task = TaskDescription(
                task_id=task_id,
                func_or_class=lambda: f"result_{task_id}",
                is_actor=False,
                is_processing=False
            )

            # æ¨¡æ‹Ÿå¹¶å‘æ£€æŸ¥
            if task.is_processing:
                skipped_log.append(f"skipped_{task_id}_{source}")
                return False

            task.is_processing = True
            task_processing_log.append(f"processed_{task_id}_{source}")
            time.sleep(0.05)

            # æ¨¡æ‹Ÿå®Œæˆ
            task.is_processing = False
            return True

        # åœºæ™¯ï¼šä»»åŠ¡åœ¨é˜Ÿåˆ—ä¸­ï¼ŒåŒæ—¶è¢«ä¸¤ä¸ªè·¯å¾„å°è¯•å¤„ç†
        task_id = "coordination_test_task"

        # Worker Loop å–å‡ºä»»åŠ¡
        worker_result = mock_process_task_with_logging(task_id, "worker")

        # Re-evaluation åŒæ—¶å°è¯•å¤„ç†
        reeval_result = mock_process_task_with_logging(task_id, "reeval")

        # éªŒè¯ï¼šåªæœ‰ä¸€ä¸ªæˆåŠŸå¤„ç†ï¼Œå¦ä¸€ä¸ªè¢«é˜»æ­¢
        processed_count = len([log for log in task_processing_log if log.startswith("processed_")])
        skipped_count = len(skipped_log)

        assert processed_count == 1, f"âœ— é¢„æœŸå¤„ç†1æ¬¡ï¼Œå®é™…{processed_count}æ¬¡"
        assert skipped_count == 1, f"âœ— é¢„æœŸè·³è¿‡1æ¬¡ï¼Œå®é™…{skipped_count}æ¬¡"

        # éªŒè¯ï¼šä¸¤ä¸ªè·¯å¾„éƒ½å°è¯•äº†å¤„ç†
        assert "processed_coordination_test_task_worker" in task_processing_log or \
               "processed_coordination_test_task_reeval" in task_processing_log, "âœ— æ²¡æœ‰è·¯å¾„æˆåŠŸå¤„ç†"

        # éªŒè¯ï¼šä¸€ä¸ªè·¯å¾„è·³è¿‡äº†
        assert "skipped_coordination_test_task_worker" in skipped_log or \
               "skipped_coordination_test_task_reeval" in skipped_log, "âœ— æ²¡æœ‰è·¯å¾„è¢«è·³è¿‡"

        print("âœ“ Worker Loop å’Œ Re-evaluation åä½œæ­£ç¡®ï¼Œæ²¡æœ‰å¹¶å‘å†²çª")
        print(f"  - æˆåŠŸå¤„ç†: {processed_count} æ¬¡")
        print(f"  - è·³è¿‡é‡å¤æ‰§è¡Œ: {skipped_count} æ¬¡")
        return True

    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_queued_tasks_state_consistency():
    """æµ‹è¯•ï¼šé˜Ÿåˆ—çŠ¶æ€ä¸€è‡´æ€§éªŒè¯"""
    print("\n=== æµ‹è¯•ï¼šé˜Ÿåˆ—çŠ¶æ€ä¸€è‡´æ€§ ===")

    try:
        # åˆ›å»ºæ¨¡æ‹Ÿçš„ä»»åŠ¡
        tasks = [
            TaskDescription(
                task_id=f"task_{i}",
                func_or_class=lambda: f"result_{i}",
                is_actor=False,
                is_processing=False
            )
            for i in range(5)
        ]

        print(f"âœ“ åˆ›å»ºäº† {len(tasks)} ä¸ªæµ‹è¯•ä»»åŠ¡")

        # æ¨¡æ‹Ÿé˜Ÿåˆ—çŠ¶æ€è·Ÿè¸ª
        queued_tasks = tasks.copy()

        # æ¨¡æ‹Ÿä»»åŠ¡è¢«å–å‡ºå’Œæ‰§è¡Œ
        processed_tasks = []
        for task in tasks[:3]:  # å¤„ç†å‰3ä¸ª
            if not task.is_processing:
                task.is_processing = True
                processed_tasks.append(task)
                # æ¨¡æ‹Ÿæ‰§è¡Œå®Œæˆ
                task.is_processing = False

        # éªŒè¯çŠ¶æ€ä¸€è‡´æ€§
        remaining_in_queue = len(queued_tasks) - len(processed_tasks)
        print(f"âœ“ å·²å¤„ç†: {len(processed_tasks)} ä¸ªä»»åŠ¡")
        print(f"âœ“ é˜Ÿåˆ—å‰©ä½™: {remaining_in_queue} ä¸ªä»»åŠ¡")

        assert len(processed_tasks) == 3, f"âœ— é¢„æœŸå¤„ç†3ä¸ªï¼Œå®é™…{len(processed_tasks)}ä¸ª"
        assert remaining_in_queue == 2, f"âœ— é¢„æœŸå‰©ä½™2ä¸ªï¼Œå®é™…{remaining_in_queue}ä¸ª"

        print("âœ“ é˜Ÿåˆ—çŠ¶æ€ä¸€è‡´æ€§æ­£ç¡®")
        return True

    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯•ä»»åŠ¡èµ„æºæ¢å¤å’Œå¹¶å‘åè°ƒ...")
    print("=" * 60)

    results = []

    # Test 3.1: èµ„æºæ¢å¤åé‡æ–°è¯„ä¼°
    try:
        results.append(("3.1", test_resource_recovery_re_evaluation()))
    except AssertionError as e:
        print(f"âœ— æµ‹è¯• 3.1 å¤±è´¥: {e}")
        results.append(("3.1", False))

    # Test 3.2: Worker Loop å’Œ Re-evaluation åä½œ
    try:
        results.append(("3.2", test_worker_loop_re_evaluation_coordination()))
    except AssertionError as e:
        print(f"âœ— æµ‹è¯• 3.2 å¤±è´¥: {e}")
        results.append(("3.2", False))

    # Test: é˜Ÿåˆ—çŠ¶æ€ä¸€è‡´æ€§
    try:
        results.append(("consistency", test_queued_tasks_state_consistency()))
    except AssertionError as e:
        print(f"âœ— æµ‹è¯• consistency å¤±è´¥: {e}")
        results.append(("consistency", False))

    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»:")
    print("-" * 60)

    total_tests = len(results)
    passed_tests = sum(1 for _, success in results if success)
    failed_tests = total_tests - passed_tests

    print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
    print(f"é€šè¿‡: {passed_tests}")
    print(f"å¤±è´¥: {failed_tests}")
    print(f"æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")

    if passed_tests == total_tests:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ä»»åŠ¡èµ„æºæ¢å¤å’Œå¹¶å‘åè°ƒæœ‰æ•ˆï¼")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
        failed_list = [name for name, success in results if not success]
        print(f"å¤±è´¥çš„æµ‹è¯•: {failed_list}")

    print("=" * 60)
