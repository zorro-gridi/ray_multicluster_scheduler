"""
Cluster manager that handles cluster configurations and connections.
"""

import ray
import time
import logging
import threading
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from datetime import datetime
from ray_multicluster_scheduler.common.model import ClusterMetadata
from ray_multicluster_scheduler.common.logging import get_logger

logger = get_logger(__name__)


@dataclass
class ClusterConfig:
    """Configuration for a Ray cluster."""
    name: str
    head_address: str
    dashboard: str
    prefer: bool = False
    weight: float = 1.0
    runtime_env: Optional[Dict[str, Any]] = None  # æ–°å¢ï¼šè¿è¡Œæ—¶ç¯å¢ƒé…ç½®ï¼ŒåŒ…å«condaå’Œhome_dirç­‰ä¿¡æ¯
    tags: List[str] = field(default_factory=list)


@dataclass
class ClusterHealth:
    """Health status information for a cluster."""
    score: float = 0.0
    resources: Dict[str, Any] = field(default_factory=dict)
    available: bool = True
    last_checked: datetime = field(default_factory=datetime.now)
    error_message: str = ""

    def update(self, score: float, resources: Dict[str, Any], available: bool, error_message: str = ""):
        """Update cluster health status."""
        self.score = score
        self.resources = resources
        self.available = available
        self.last_checked = datetime.now()
        self.error_message = error_message


class ClusterManager:
    """Manages Ray cluster configurations and connections."""

    def __init__(self):
        """Initialize the cluster manager."""
        self.clusters: Dict[str, ClusterConfig] = {}
        self.health_status: Dict[str, ClusterHealth] = {}
        self.active_connections: Dict[str, Dict[str, Any]] = {}
        self._lock = threading.RLock()
        self.metrics = {
            "total_checks": 0,
            "successful_checks": 0,
            "failed_checks": 0,
            "last_refresh": None
        }

    def add_cluster(self, config: ClusterConfig):
        """Add a cluster configuration."""
        self.clusters[config.name] = config
        self.health_status[config.name] = ClusterHealth()
        logger.info(f"Added cluster configuration: {config.name}")

    def remove_cluster(self, name: str):
        """Remove a cluster configuration."""
        if name in self.clusters:
            del self.clusters[name]
            del self.health_status[name]
            logger.info(f"Removed cluster configuration: {name}")

    def get_cluster_config(self, name: str) -> Optional[ClusterConfig]:
        """Get cluster configuration by name."""
        return self.clusters.get(name)

    def get_all_cluster_configs(self) -> Dict[str, ClusterConfig]:
        """Get all cluster configurations."""
        return self.clusters.copy()

    def get_cluster_home_dir(self, cluster_name: str) -> Optional[str]:
        """Get the home directory for a specific cluster."""
        config = self.get_cluster_config(cluster_name)
        if config and config.runtime_env:
            env_vars = config.runtime_env.get('env_vars', {})
            return env_vars.get('home_dir')
        return None

    def _log_cluster_configurations(self):
        """Log cluster configurations for debugging."""
        logger.info("ğŸ“‹ é›†ç¾¤ä¿¡æ¯å’Œèµ„æºä½¿ç”¨æƒ…å†µ:")
        logger.info("=" * 50)

        if not self.clusters:
            logger.info("ğŸš« å½“å‰æ²¡æœ‰é…ç½®é›†ç¾¤")
            return

        for name, config in self.clusters.items():
            health = self.health_status.get(name, ClusterHealth())
            status = "ğŸŸ¢ å¥åº·" if health.available else "ğŸ”´ ä¸å¥åº·"
            score = f"{health.score:.1f}" if health.score >= 0 else "N/A"

            logger.info(f"é›†ç¾¤ [{name}]: {status}")
            logger.info(f"  åœ°å€: {config.head_address}")
            logger.info(f"  é¦–é€‰é¡¹: {'æ˜¯' if config.prefer else 'å¦'}")
            logger.info(f"  æƒé‡: {config.weight}")

            # ä»runtime_envä¸­æå–home_dirä¿¡æ¯
            home_dir = "æœªè®¾ç½®"
            if config.runtime_env:
                env_vars = config.runtime_env.get('env_vars', {})
                home_dir = env_vars.get('home_dir', 'æœªè®¾ç½®')
            logger.info(f"  Homeç›®å½•: {home_dir}")

            logger.info(f"  è¯„åˆ†: {score}")
            logger.info(f"  æ ‡ç­¾: {', '.join(config.tags)}")

            if health.resources:
                cpu_free = health.resources.get('cpu_free', 0)
                cpu_total = health.resources.get('cpu_total', 0)
                gpu_free = health.resources.get('gpu_free', 0)
                gpu_total = health.resources.get('gpu_total', 0)
                node_count = health.resources.get('node_count', 0)

                logger.info(f"  CPU: {cpu_free}/{cpu_total}")
                logger.info(f"  GPU: {gpu_free}/{gpu_total}")
                logger.info(f"  èŠ‚ç‚¹æ•°: {node_count}")

            logger.info("-" * 30)

    def refresh_all_clusters(self):
        """Refresh health status for all clusters."""
        with self._lock:
            logger.info("å¼€å§‹åˆ·æ–°é›†ç¾¤çŠ¶æ€...")

            for name, config in self.clusters.items():
                try:
                    health = self._check_cluster_health(config)
                    self.health_status[name] = health

                    if health.available:
                        self.metrics["successful_checks"] += 1
                    else:
                        self.metrics["failed_checks"] += 1

                except Exception as e:
                    logger.error(f"æ£€æŸ¥é›†ç¾¤ {name} å¥åº·çŠ¶æ€æ—¶å‡ºé”™: {e}")
                    import traceback
                    traceback.print_exc()
                    self.metrics["failed_checks"] += 1
                    # Update health status with error
                    error_health = ClusterHealth()
                    error_health.update(-1, {}, False, str(e))
                    self.health_status[name] = error_health

            self.metrics["total_checks"] += 1
            self.metrics["last_refresh"] = datetime.now()
            logger.info(f"é›†ç¾¤çŠ¶æ€åˆ·æ–°å®Œæˆï¼Œæ€»è®¡æ£€æŸ¥: {self.metrics['total_checks']}")

    def _check_cluster_health(self, config: ClusterConfig) -> ClusterHealth:
        """æ£€æŸ¥å•ä¸ªé›†ç¾¤å¥åº·çŠ¶æ€"""
        health = ClusterHealth()
        ray_address = f"ray://{config.head_address}"

        try:
            # å°è¯•è¿æ¥åˆ°é›†ç¾¤ï¼Œæ·»åŠ è¶…æ—¶æœºåˆ¶
            import socket
            host, port = config.head_address.split(':')
            port = int(port)

            # å…ˆæ£€æŸ¥ç«¯å£æ˜¯å¦å¯è¾¾
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)  # 5ç§’è¶…æ—¶
            result = sock.connect_ex((host, port))
            sock.close()

            if result != 0:
                health.update(-1, {}, False, f"æ— æ³•è¿æ¥åˆ°é›†ç¾¤åœ°å€ {config.head_address}")
                return health

            # å°è¯•è¿æ¥åˆ°é›†ç¾¤
            ray.init(
                address=ray_address,
                ignore_reinit_error=True,
                logging_level=logging.WARNING,
                _system_config={"num_heartbeats_timeout": 10}
            )

            # ç­‰å¾…è¿æ¥ç¨³å®š
            time.sleep(0.5)

            if not ray.is_initialized():
                health.update(-1, {}, False, "Rayæœªæ­£ç¡®åˆå§‹åŒ–")
                return health

            # è·å–èµ„æºä¿¡æ¯
            avail_resources = ray.available_resources()
            total_resources = ray.cluster_resources()

            # å¤„ç†MACé›†ç¾¤çš„ç‰¹æ®ŠCPUèµ„æº
            # å¯¹äºMACé›†ç¾¤ï¼Œæˆ‘ä»¬éœ€è¦åŒæ—¶è€ƒè™‘CPUå’ŒMacCPUèµ„æº
            cpu_free, cpu_total = self._calculate_cpu_resources(avail_resources, total_resources, config)

            gpu_free = avail_resources.get("GPU", 0)
            gpu_total = total_resources.get("GPU", 0)

            if cpu_free <= 0:
                score = -1
            else:
                # åŸºç¡€è¯„åˆ† = å¯ç”¨CPU * é›†ç¾¤æƒé‡
                base_score = cpu_free * config.weight
                # GPU èµ„æºåŠ æˆ
                gpu_bonus = gpu_free * 5  # GPUèµ„æºæ›´å®è´µ

                # åå¥½é›†ç¾¤åŠ æˆ
                preference_bonus = 1.2 if config.prefer else 1.0

                # è´Ÿè½½å‡è¡¡å› å­ï¼šèµ„æºåˆ©ç”¨ç‡è¶Šä½å¾—åˆ†è¶Šé«˜
                cpu_utilization = (cpu_total - cpu_free) / cpu_total if cpu_total > 0 else 0
                load_balance_factor = 1.0 - cpu_utilization  # è´Ÿè½½è¶Šä½å› å­è¶Šé«˜

                # æœ€ç»ˆè¯„åˆ†
                score = (base_score + gpu_bonus) * preference_bonus * load_balance_factor

            # æ”¶é›†èµ„æºè¯¦æƒ…
            node_count = len(ray.nodes())
            resources = {
                "available": avail_resources,
                "total": total_resources,
                "cpu_free": cpu_free,
                "cpu_total": cpu_total,
                "gpu_free": gpu_free,
                "gpu_total": gpu_total,
                "cpu_utilization": cpu_utilization,
                "node_count": node_count
            }

            health.update(score, resources, True)

            # è®°å½•è¯¦ç»†çš„èµ„æºä¿¡æ¯
            logger.info(f"é›†ç¾¤ [{config.name}] èµ„æºçŠ¶æ€: "
                       f"CPU={cpu_free}/{cpu_total} ({cpu_utilization:.1%} å·²ä½¿ç”¨), "
                       f"GPU={gpu_free}/{gpu_total}, "
                       f"èŠ‚ç‚¹æ•°={node_count}, "
                       f"è¯„åˆ†={score:.1f}")

            # æ–­å¼€è¿æ¥ä»¥é¿å…å ç”¨èµ„æº
            ray.shutdown()

        except Exception as e:
            logger.warning(f"é›†ç¾¤ [{config.name}] è¿æ¥å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            health.update(-1, {}, False, str(e))

        return health

    def _calculate_cpu_resources(self, avail_resources: Dict[str, Any],
                                total_resources: Dict[str, Any],
                                config: ClusterConfig) -> tuple:
        """
        è®¡ç®—CPUèµ„æºï¼Œç‰¹åˆ«å¤„ç†MACé›†ç¾¤çš„ç‰¹æ®Šèµ„æºç±»å‹

        Args:
            avail_resources: å¯ç”¨èµ„æºå­—å…¸
            total_resources: æ€»èµ„æºå­—å…¸
            config: é›†ç¾¤é…ç½®

        Returns:
            tuple: (cpu_free, cpu_total)
        """
        # é»˜è®¤ä½¿ç”¨æ ‡å‡†CPUèµ„æº
        cpu_free = avail_resources.get("CPU", 0)
        cpu_total = total_resources.get("CPU", 0)

        # å¯¹äºMACé›†ç¾¤ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰MacCPUèµ„æº
        if "mac" in config.name.lower() or any("mac" in tag.lower() for tag in config.tags):
            mac_cpu_free = avail_resources.get("MacCPU", 0)
            mac_cpu_total = total_resources.get("MacCPU", 0)

            # å¦‚æœMacCPUèµ„æºæ›´å¤§ï¼Œåˆ™ä½¿ç”¨MacCPUèµ„æº
            if mac_cpu_total > cpu_total:
                cpu_free = mac_cpu_free
                cpu_total = mac_cpu_total
                logger.debug(f"ä½¿ç”¨MACç‰¹æ®ŠCPUèµ„æº: å¯ç”¨={cpu_free}, æ€»è®¡={cpu_total}")

        return cpu_free, cpu_total

    def select_best_cluster(self, required_resources: Dict[str, float] = None) -> Optional[str]:
        """Select the best cluster based on health scores and resource requirements."""
        if required_resources is None:
            required_resources = {}

        # Filter healthy clusters
        healthy_clusters = {
            name: self.health_status[name]
            for name in self.clusters
            if self.health_status[name].available
        }

        # Filter clusters with sufficient resources
        sufficient_clusters = {}
        for name, health in healthy_clusters.items():
            resources = health.resources
            available_cpu = resources.get("cpu_free", 0)
            available_gpu = resources.get("gpu_free", 0)
            required_cpu = required_resources.get("CPU", 0)
            required_gpu = required_resources.get("GPU", 0)

            if available_cpu >= required_cpu and available_gpu >= required_gpu:
                sufficient_clusters[name] = health

        # Check if we have any sufficient clusters
        if not sufficient_clusters:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°æ»¡è¶³èµ„æºéœ€æ±‚çš„é›†ç¾¤")
            return None

        # Select the best cluster based on score
        best_cluster = max(sufficient_clusters.items(), key=lambda x: x[1].score)[0]
        best_score = sufficient_clusters[best_cluster].score

        # Log selection details
        if len(sufficient_clusters) > 1:
            # Log details for load balancing
            for name, health in sufficient_clusters.items():
                resources = health.resources
                cpu_free = resources.get("cpu_free", 0)
                cpu_total = resources.get("cpu_total", 0)
                gpu_free = resources.get("gpu_free", 0)
                gpu_total = resources.get("gpu_total", 0)
                cpu_utilization = resources.get("cpu_utilization", 0)

                logger.info(f"é›†ç¾¤ [{name}] è¯„åˆ†={health.score:.1f}, "
                           f"CPUè´Ÿè½½={cpu_utilization:.1%} ({cpu_free}/{cpu_total}), "
                           f"GPU={gpu_free}/{gpu_total}")

        logger.info(f"é€‰æ‹©æœ€ä½³é›†ç¾¤ [{best_cluster}] è¿›è¡Œè´Ÿè½½å‡è¡¡: "
                   f"è¯„åˆ†={best_score:.1f}")

        return best_cluster

    def get_best_cluster(self, requirements: Optional[Dict] = None) -> Optional[str]:
        """Get the best cluster based on current health and requirements.

        This is a wrapper method for select_best_cluster to maintain API compatibility.

        Args:
            requirements: Dictionary containing resource requirements and tags

        Returns:
            Name of the best cluster or None if no suitable cluster found
        """
        if requirements is None:
            requirements = {}

        # Extract resource requirements
        required_resources = requirements.get("resources", {})

        return self.select_best_cluster(required_resources)

    def get_or_create_connection(self, cluster_name: str):
        """è·å–æˆ–åˆ›å»ºé›†ç¾¤è¿æ¥"""
        with self._lock:
            if cluster_name in self.active_connections:
                try:
                    # éªŒè¯è¿æ¥æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
                    ray.init(
                        address=f"ray://{self.clusters[cluster_name].head_address}",
                        ignore_reinit_error=True
                    )
                    if ray.is_initialized():
                        conn_info = self.active_connections[cluster_name]
                        logger.info(f"ğŸ” ä½¿ç”¨ç°æœ‰è¿æ¥åˆ°é›†ç¾¤ [{cluster_name}] ({conn_info['address']})")
                        return self.active_connections[cluster_name]
                except:
                    # è¿æ¥æ— æ•ˆï¼Œç§»é™¤
                    del self.active_connections[cluster_name]
                    import traceback
                    traceback.print_exc()

            # åˆ›å»ºæ–°è¿æ¥
            try:
                ray_address = f"ray://{self.clusters[cluster_name].head_address}"
                logger.info(f"ğŸ”„ æ­£åœ¨åˆ›å»ºåˆ°é›†ç¾¤ [{cluster_name}] çš„æ–°è¿æ¥: {ray_address}")

                ray.init(
                    address=ray_address,
                    ignore_reinit_error=True,
                    logging_level=logging.INFO
                )

                if not ray.is_initialized():
                    raise ConnectionError("Ray è¿æ¥å¤±è´¥")

                self.active_connections[cluster_name] = {
                    "address": ray_address,
                    "created_at": datetime.now(),
                    "last_used": datetime.now()
                }

                # è·å–å¹¶æ˜¾ç¤ºé›†ç¾¤èµ„æºä¿¡æ¯
                try:
                    avail_resources = ray.available_resources()
                    total_resources = ray.cluster_resources()
                    cpu_free = avail_resources.get("CPU", 0)
                    cpu_total = total_resources.get("CPU", 0)
                    gpu_free = avail_resources.get("GPU", 0)
                    gpu_total = total_resources.get("GPU", 0)
                    node_count = len(ray.nodes())

                    logger.info(f"âœ… è¿æ¥åˆ°é›†ç¾¤ [{cluster_name}] æˆåŠŸ")
                    logger.info(f"   CPU: {cpu_free}/{cpu_total}")
                    logger.info(f"   GPU: {gpu_free}/{gpu_total}")
                    logger.info(f"   èŠ‚ç‚¹æ•°: {node_count}")
                except Exception as e:
                    logger.warning(f"è·å–é›†ç¾¤ [{cluster_name}] èµ„æºä¿¡æ¯æ—¶å‡ºé”™: {e}")

                return self.active_connections[cluster_name]

            except Exception as e:
                logger.error(f"âŒ è¿æ¥åˆ°é›†ç¾¤ [{cluster_name}] å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                return None