#!/usr/bin/env python3
"""
æ”¹è¿›ç‰ˆè´Ÿè½½å‡è¡¡ç­–ç•¥æµ‹è¯•ç”¨ä¾‹
éªŒè¯ä¼˜åŒ–åçš„è·¨é›†ç¾¤è´Ÿè½½å‡è¡¡èƒ½åŠ›
"""

import sys
import os
import time
from collections import defaultdict
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)) + '/..')

from ray_multicluster_scheduler.common.model import TaskDescription, ResourceSnapshot, ClusterMetadata
from ray_multicluster_scheduler.scheduler.policy.policy_engine import PolicyEngine


def test_improved_load_balancing():
    """æµ‹è¯•æ”¹è¿›åçš„è´Ÿè½½å‡è¡¡ç­–ç•¥"""
    print("=" * 80)
    print("ğŸ” æ”¹è¿›ç‰ˆè´Ÿè½½å‡è¡¡ç­–ç•¥æµ‹è¯•")
    print("=" * 80)

    # åˆ›å»ºç­–ç•¥å¼•æ“
    policy_engine = PolicyEngine()

    # æ¨¡æ‹Ÿé›†ç¾¤é…ç½® - centos(16æ ¸) å’Œ mac(8æ ¸)
    cluster_configs = {
        "centos": ClusterMetadata(
            name="centos",
            head_address="192.168.5.7:32546",
            dashboard="http://192.168.5.7:31591",
            prefer=False,
            weight=1.0,
            runtime_env={
                "conda": "ts",
                "env_vars": {"home_dir": "/home/zorro"}
            },
            tags=["linux", "x86_64"]
        ),
        "mac": ClusterMetadata(
            name="mac",
            head_address="192.168.5.2:32546",
            dashboard="http://192.168.5.2:8265",
            prefer=True,
            weight=1.2,
            runtime_env={
                "conda": "k8s",
                "env_vars": {"home_dir": "/Users/zorro"}
            },
            tags=["macos", "arm64"]
        )
    }

    # æ›´æ–°ç­–ç•¥å¼•æ“çš„é›†ç¾¤å…ƒæ•°æ®
    policy_engine.update_cluster_metadata(cluster_configs)

    # æ¨¡æ‹Ÿé›†ç¾¤èµ„æºå¿«ç…§ - centosæœ‰16ä¸ªCPUï¼Œmacæœ‰8ä¸ªCPU
    current_time = time.time()
    cluster_snapshots = {
        "centos": ResourceSnapshot(
            cluster_name="centos",
            total_resources={"CPU": 16.0, "GPU": 0},
            available_resources={"CPU": 16.0, "GPU": 0},
            node_count=2,
            timestamp=current_time
        ),
        "mac": ResourceSnapshot(
            cluster_name="mac",
            total_resources={"CPU": 8.0, "GPU": 0, "MacCPU": 8.0},
            available_resources={"CPU": 8.0, "GPU": 0, "MacCPU": 8.0},
            node_count=1,
            timestamp=current_time
        )
    }

    # ç»Ÿè®¡å˜é‡
    cluster_distribution = defaultdict(int)
    queued_tasks = 0

    # æäº¤30ä¸ªä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡éœ€è¦2ä¸ªCPUï¼Œä¸æŒ‡å®šé›†ç¾¤ï¼ˆä½¿ç”¨è´Ÿè½½å‡è¡¡ï¼‰
    # æ€»å…±éœ€è¦60ä¸ªCPUï¼Œä½†ä¸¤ä¸ªé›†ç¾¤æ€»å…±åªæœ‰24ä¸ªCPU
    print(f"\nğŸš€ æäº¤30ä¸ªä»»åŠ¡ï¼ˆæ¯ä¸ªä»»åŠ¡éœ€è¦2ä¸ªCPUï¼Œä¸æŒ‡å®šé›†ç¾¤ï¼‰:")
    print(f"   â€¢ centosé›†ç¾¤: 16ä¸ªCPU")
    print(f"   â€¢ macé›†ç¾¤: 8ä¸ªCPU")
    print(f"   â€¢ æ€»å¯ç”¨CPU: 24ä¸ª")
    print(f"   â€¢ æ€»éœ€æ±‚CPU: 60ä¸ª (30ä¸ªä»»åŠ¡ Ã— 2ä¸ªCPU)")
    print(f"   â€¢ åº”è¯¥æœ‰12ä¸ªä»»åŠ¡ç«‹å³è°ƒåº¦ï¼Œ18ä¸ªä»»åŠ¡æ’é˜Ÿ")

    for i in range(30):
        task_desc = TaskDescription(
            task_id=f"improved_lb_task_{i}",
            name=f"improved_lb_task_{i}",
            func_or_class=lambda: None,
            args=(),
            kwargs={},
            resource_requirements={"CPU": 2.0},
            tags=["test", "load_balance"],
            preferred_cluster=None  # ä¸æŒ‡å®šé›†ç¾¤ï¼Œä½¿ç”¨è´Ÿè½½å‡è¡¡
        )

        # è®©ç­–ç•¥å¼•æ“åšè°ƒåº¦å†³ç­–
        decision = policy_engine.schedule(task_desc, cluster_snapshots)

        if decision and decision.cluster_name:
            cluster_distribution[decision.cluster_name] += 1
            print(f"    ä»»åŠ¡ {i}: è°ƒåº¦åˆ° {decision.cluster_name} - {decision.reason}")
        else:
            queued_tasks += 1
            print(f"    ä»»åŠ¡ {i}: è¿›å…¥é˜Ÿåˆ—ç­‰å¾…")

    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡:")
    generate_improved_lb_test_report(cluster_distribution, queued_tasks, cluster_snapshots, cluster_configs)

    return cluster_distribution, queued_tasks


def generate_improved_lb_test_report(cluster_distribution, queued_tasks, cluster_snapshots, cluster_configs):
    """ç”Ÿæˆæ”¹è¿›ç‰ˆè´Ÿè½½å‡è¡¡æµ‹è¯•æŠ¥å‘Š"""
    print(f"\nğŸ“‹ é›†ç¾¤åˆ†å¸ƒç»Ÿè®¡:")
    total_scheduled = sum(cluster_distribution.values())

    for cluster_name, count in cluster_distribution.items():
        # è·å–é›†ç¾¤ä¿¡æ¯
        snapshot = cluster_snapshots.get(cluster_name)
        config = cluster_configs.get(cluster_name)
        if snapshot and config:
            cpu_total = snapshot.total_resources.get("CPU", 0)
            cpu_available = snapshot.available_resources.get("CPU", 0)

            # å¯¹äºMACé›†ç¾¤ï¼Œæ£€æŸ¥MacCPUèµ„æº
            if "mac" in cluster_name.lower():
                mac_cpu_total = snapshot.total_resources.get("MacCPU", 0)
                mac_cpu_available = snapshot.available_resources.get("MacCPU", 0)
                if mac_cpu_total > cpu_total:
                    cpu_total = mac_cpu_total
                    cpu_available = mac_cpu_available

            print(f"  â€¢ {cluster_name}: {count}ä¸ªä»»åŠ¡ (æ€»CPU: {cpu_total}, å¯ç”¨CPU: {cpu_available}, æƒé‡: {config.weight})")
        else:
            print(f"  â€¢ {cluster_name}: {count}ä¸ªä»»åŠ¡")

    print(f"\nğŸ“‹ é˜Ÿåˆ—ç»Ÿè®¡:")
    print(f"  â€¢ ç«‹å³è°ƒåº¦ä»»åŠ¡: {total_scheduled}ä¸ª")
    print(f"  â€¢ è¿›å…¥é˜Ÿåˆ—ä»»åŠ¡: {queued_tasks}ä¸ª")
    print(f"  â€¢ æ€»ä»»åŠ¡æ•°: {total_scheduled + queued_tasks}ä¸ª")

    # åˆ†æè°ƒåº¦è¡Œä¸º
    print(f"\nğŸ“‹ è°ƒåº¦è¡Œä¸ºåˆ†æ:")
    if len(cluster_distribution) > 1:
        print(f"  âœ… ç³»ç»Ÿèƒ½å¤Ÿå°†ä»»åŠ¡åˆ†æ•£åˆ°å¤šä¸ªé›†ç¾¤è¿›è¡Œè°ƒåº¦")
        print(f"     â€¢ ä¸åŒé›†ç¾¤éƒ½æœ‰ä»»åŠ¡è¢«è°ƒåº¦")
        print(f"     â€¢ å®ç°äº†è·¨é›†ç¾¤è´Ÿè½½å‡è¡¡")

        # è®¡ç®—è´Ÿè½½å‡è¡¡ç¨‹åº¦
        counts = list(cluster_distribution.values())
        max_count = max(counts)
        min_count = min(counts)
        balance_ratio = min_count / max_count if max_count > 0 else 0

        print(f"     â€¢ è´Ÿè½½å‡è¡¡æ¯”ç‡: {balance_ratio:.2f} (è¶Šæ¥è¿‘1è¶Šå‡è¡¡)")
    else:
        print(f"  âš ï¸  ç³»ç»Ÿå¯èƒ½åªåœ¨ä¸€ä¸ªé›†ç¾¤ä¸Šè¿›è¡Œè°ƒåº¦")
        print(f"     â€¢ åªæœ‰ä¸€ä¸ªé›†ç¾¤æœ‰ä»»åŠ¡è¢«è°ƒåº¦")
        print(f"     â€¢ å¯èƒ½æœªå……åˆ†åˆ©ç”¨æ‰€æœ‰å¯ç”¨é›†ç¾¤")

    # åˆ†æèµ„æºåˆ©ç”¨æƒ…å†µ
    print(f"\nğŸ“‹ èµ„æºåˆ©ç”¨åˆ†æ:")
    total_capacity = 0
    for cluster_name, snapshot in cluster_snapshots.items():
        config = cluster_configs.get(cluster_name)
        cpu_total = snapshot.total_resources.get("CPU", 0)
        # å¯¹äºMACé›†ç¾¤ï¼Œæ£€æŸ¥MacCPUèµ„æº
        if config and "mac" in cluster_name.lower():
            mac_cpu_total = snapshot.total_resources.get("MacCPU", 0)
            if mac_cpu_total > cpu_total:
                cpu_total = mac_cpu_total
        total_capacity += cpu_total

    total_required = (total_scheduled + queued_tasks) * 2  # æ¯ä¸ªä»»åŠ¡éœ€è¦2ä¸ªCPU
    utilization_rate = (total_scheduled * 2) / total_capacity if total_capacity > 0 else 0

    print(f"  â€¢ æ€»é›†ç¾¤å®¹é‡: {total_capacity}ä¸ªCPU")
    print(f"  â€¢ æ€»ä»»åŠ¡éœ€æ±‚: {total_required}ä¸ªCPU")
    print(f"  â€¢ å®é™…è°ƒåº¦ä»»åŠ¡: {total_scheduled}ä¸ª (æ¶ˆè€—{total_scheduled * 2}ä¸ªCPU)")
    print(f"  â€¢ èµ„æºåˆ©ç”¨ç‡: {utilization_rate:.1%}")
    print(f"  â€¢ æ’é˜Ÿä»»åŠ¡æ•°: {queued_tasks}ä¸ª")


def compare_before_after():
    """æ¯”è¾ƒæ”¹è¿›å‰åçš„æ•ˆæœ"""
    print("\n" + "=" * 80)
    print("ğŸ”„ æ”¹è¿›å‰åæ•ˆæœå¯¹æ¯”")
    print("=" * 80)

    print(f"\nğŸ“‹ æ”¹è¿›å‰çš„é—®é¢˜:")
    print(f"  1. è¯„åˆ†ç­–ç•¥è¿‡äºç®€åŒ–:")
    print(f"     â€¢ ä½¿ç”¨å›ºå®šå€¼è¿›è¡Œå½’ä¸€åŒ–å¯¼è‡´è¯„åˆ†å¤±çœŸ")
    print(f"     â€¢ æœªè€ƒè™‘é›†ç¾¤æƒé‡ã€åå¥½å’ŒçœŸå®è´Ÿè½½")
    print(f"     â€¢ æœªæ­£ç¡®å¤„ç†MACé›†ç¾¤çš„ç‰¹æ®ŠCPUèµ„æº")

    print(f"\n  2. è´Ÿè½½å‡è¡¡æ•ˆæœå·®:")
    print(f"     â€¢ æ‰€æœ‰ä»»åŠ¡éƒ½è¢«è°ƒåº¦åˆ°åŒä¸€ä¸ªé›†ç¾¤")
    print(f"     â€¢ æœªå……åˆ†åˆ©ç”¨å¤šé›†ç¾¤èµ„æº")
    print(f"     â€¢ æ— æ³•å®ç°çœŸæ­£çš„è´Ÿè½½å‡è¡¡")

    print(f"\nğŸ“‹ æ”¹è¿›åçš„ä¼˜åŠ¿:")
    print(f"  1. å¢å¼ºç‰ˆè¯„åˆ†ç­–ç•¥:")
    print(f"     â€¢ åŸºäºå®é™…èµ„æºé…ç½®è¿›è¡Œè¯„åˆ†")
    print(f"     â€¢ è€ƒè™‘é›†ç¾¤æƒé‡ã€åå¥½å’Œè´Ÿè½½å› å­")
    print(f"     â€¢ æ­£ç¡®å¤„ç†MACé›†ç¾¤çš„ç‰¹æ®ŠCPUèµ„æº")

    print(f"\n  2. æ›´å¥½çš„è´Ÿè½½å‡è¡¡:")
    print(f"     â€¢ ä»»åŠ¡èƒ½å¤Ÿåˆ†æ•£åˆ°å¤šä¸ªé›†ç¾¤")
    print(f"     â€¢ å……åˆ†åˆ©ç”¨æ‰€æœ‰å¯ç”¨é›†ç¾¤èµ„æº")
    print(f"     â€¢ å®ç°æ›´åˆç†çš„ä»»åŠ¡åˆ†é…")


def main():
    # è¿è¡Œæ”¹è¿›ç‰ˆè´Ÿè½½å‡è¡¡æµ‹è¯•
    cluster_dist, queued = test_improved_load_balancing()

    # æ¯”è¾ƒæ”¹è¿›å‰åæ•ˆæœ
    compare_before_after()

    print("\n" + "=" * 80)
    print("ğŸ æµ‹è¯•æ€»ç»“")
    print("=" * 80)

    total_scheduled = sum(cluster_dist.values())
    if len(cluster_dist) > 1:
        print(f"âœ… æ”¹è¿›åçš„ç³»ç»Ÿèƒ½å¤Ÿå®ç°è·¨é›†ç¾¤è´Ÿè½½å‡è¡¡")
        print(f"   â€¢ ä»»åŠ¡è¢«åˆ†æ•£åˆ°å¤šä¸ªé›†ç¾¤æ‰§è¡Œ")
        print(f"   â€¢ å……åˆ†åˆ©ç”¨äº†æ‰€æœ‰å¯ç”¨é›†ç¾¤çš„èµ„æº")

        # è®¡ç®—è´Ÿè½½å‡è¡¡ç¨‹åº¦
        counts = list(cluster_dist.values())
        max_count = max(counts)
        min_count = min(counts)
        balance_ratio = min_count / max_count if max_count > 0 else 0

        print(f"   â€¢ è´Ÿè½½å‡è¡¡æ¯”ç‡: {balance_ratio:.2f}")
    else:
        print(f"âš ï¸  æ”¹è¿›åçš„ç³»ç»Ÿä»å­˜åœ¨è°ƒåº¦å±€é™æ€§")
        print(f"   â€¢ ä»»åŠ¡ä¸»è¦é›†ä¸­åœ¨å•ä¸ªé›†ç¾¤æ‰§è¡Œ")
        print(f"   â€¢ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")

    print(f"\nğŸ“ˆ è°ƒåº¦ç»Ÿè®¡:")
    print(f"   â€¢ ç«‹å³è°ƒåº¦ä»»åŠ¡: {total_scheduled}ä¸ª")
    print(f"   â€¢ è¿›å…¥é˜Ÿåˆ—ä»»åŠ¡: {queued}ä¸ª")
    for cluster, count in cluster_dist.items():
        print(f"   â€¢ {cluster}é›†ç¾¤: {count}ä¸ªä»»åŠ¡")


if __name__ == "__main__":
    main()