#!/usr/bin/env python3
"""
çœŸå®é›†ç¾¤è¿æ¥è´Ÿè½½å‡è¡¡æµ‹è¯•ç”¨ä¾‹
ä½¿ç”¨å®é™…é›†ç¾¤è¿æ¥éªŒè¯æ”¹è¿›åçš„è´Ÿè½½å‡è¡¡ç­–ç•¥
"""

import sys
import os
import time
import ray
from collections import defaultdict
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)) + '/..')

from ray_multicluster_scheduler.app.client_api.unified_scheduler import (
    UnifiedScheduler, 
    initialize_scheduler_environment, 
    submit_task
)
from ray_multicluster_scheduler.scheduler.monitor.cluster_monitor import ClusterMonitor
from ray_multicluster_scheduler.scheduler.policy.policy_engine import PolicyEngine
from ray_multicluster_scheduler.common.model import TaskDescription


# ç”¨äºæ”¶é›†ç»Ÿè®¡æ•°æ®çš„å…¨å±€å˜é‡
task_statistics = {
    'total_submitted': 0,
    'total_completed': 0,
    'cluster_distribution': defaultdict(int),
    'task_results': [],
    'errors': []
}


def test_task(task_id, task_name, duration=1):
    """æµ‹è¯•ä»»åŠ¡å‡½æ•°"""
    import time
    import ray
    
    start_time = time.time()
    print(f"[{ray.util.get_node_ip_address()}] ä»»åŠ¡ {task_id} ({task_name}) å¼€å§‹æ‰§è¡Œ")
    time.sleep(duration)
    result = f"[{ray.util.get_node_ip_address()}] ä»»åŠ¡ {task_id} ({task_name}) æ‰§è¡Œå®Œæˆ"
    print(result)
    
    # æ›´æ–°ç»Ÿè®¡æ•°æ®
    with threading.Lock():
        task_statistics['total_completed'] += 1
        task_statistics['cluster_distribution'][ray.util.get_node_ip_address()] += 1
        task_statistics['task_results'].append({
            'task_id': task_id,
            'task_name': task_name,
            'result': result,
            'execution_time': time.time() - start_time
        })
    
    return result


def test_real_cluster_load_balancing():
    """ä½¿ç”¨çœŸå®é›†ç¾¤è¿æ¥æµ‹è¯•è´Ÿè½½å‡è¡¡"""
    print("=" * 80)
    print("ğŸ” çœŸå®é›†ç¾¤è¿æ¥è´Ÿè½½å‡è¡¡æµ‹è¯•")
    print("=" * 80)
    
    try:
        # 1. åˆå§‹åŒ–è°ƒåº¦ç¯å¢ƒ
        print("ğŸ”§ åˆå§‹åŒ–è°ƒåº¦ç¯å¢ƒ...")
        initialize_scheduler_environment()
        print("âœ… è°ƒåº¦ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
        
        # 2. åˆ›å»ºç»Ÿä¸€è°ƒåº¦å™¨
        print("ğŸ”§ åˆ›å»ºç»Ÿä¸€è°ƒåº¦å™¨...")
        scheduler = UnifiedScheduler()
        print("âœ… ç»Ÿä¸€è°ƒåº¦å™¨åˆ›å»ºå®Œæˆ")
        
        # 3. åˆå§‹åŒ–è°ƒåº¦ç¯å¢ƒ
        print("ğŸ”§ åˆå§‹åŒ–è°ƒåº¦ç¯å¢ƒ...")
        task_lifecycle_manager = scheduler.initialize_environment()
        print("âœ… è°ƒåº¦ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
        
        # 4. ç­‰å¾…é›†ç¾¤è¿æ¥å»ºç«‹
        print("â³ ç­‰å¾…é›†ç¾¤è¿æ¥å»ºç«‹...")
        time.sleep(5)  # ç»™é›†ç¾¤ä¸€äº›æ—¶é—´å»ºç«‹è¿æ¥
        
        # 5. æ˜¾ç¤ºé›†ç¾¤çŠ¶æ€
        print("ğŸ“‹ é›†ç¾¤çŠ¶æ€:")
        cluster_monitor = task_lifecycle_manager.cluster_monitor
        cluster_info = cluster_monitor.get_all_cluster_info()
        
        for cluster_name, info in cluster_info.items():
            if info and 'snapshot' in info and info['snapshot']:
                snapshot = info['snapshot']
                cpu_available = snapshot.available_resources.get("CPU", 0)
                cpu_total = snapshot.total_resources.get("CPU", 0)
                gpu_available = snapshot.available_resources.get("GPU", 0)
                gpu_total = snapshot.total_resources.get("GPU", 0)
                
                print(f"  â€¢ {cluster_name}: CPU={cpu_available}/{cpu_total}, GPU={gpu_available}/{gpu_total}")
            else:
                print(f"  â€¢ {cluster_name}: æ— æ³•è·å–èµ„æºä¿¡æ¯")
        
        # 5. æäº¤æµ‹è¯•ä»»åŠ¡
        print(f"\nğŸš€ æäº¤æµ‹è¯•ä»»åŠ¡...")
        futures = []
        
        # æäº¤10ä¸ªä»»åŠ¡ï¼Œä¸æŒ‡å®šé›†ç¾¤ï¼ˆä½¿ç”¨è´Ÿè½½å‡è¡¡ï¼‰
        for i in range(10):
            task_id = f"real_lb_task_{i}"
            try:
                task_id, future = submit_task(
                    func=test_task,
                    args=(task_id, f"è´Ÿè½½å‡è¡¡ä»»åŠ¡{i}", 1),
                    resource_requirements={"CPU": 1.0},
                    name=f"è´Ÿè½½å‡è¡¡ä»»åŠ¡{i}"
                )
                futures.append((task_id, future))
                task_statistics['total_submitted'] += 1
                print(f"    âœ“ æäº¤ä»»åŠ¡ {task_id}")
            except Exception as e:
                print(f"    âœ— æäº¤ä»»åŠ¡ {task_id} å¤±è´¥: {e}")
                task_statistics['errors'].append(f"ä»»åŠ¡ {task_id} æäº¤å¤±è´¥: {e}")
        
        # 6. ç­‰å¾…ä»»åŠ¡å®Œæˆ
        print(f"\nâ³ ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
        completed_tasks = 0
        for task_id, future in futures:
            try:
                result = ray.get(future, timeout=30)  # 30ç§’è¶…æ—¶
                print(f"    âœ“ ä»»åŠ¡ {task_id} å®Œæˆ: {result}")
                completed_tasks += 1
            except Exception as e:
                print(f"    âœ— ä»»åŠ¡ {task_id} å¤±è´¥: {e}")
                task_statistics['errors'].append(f"ä»»åŠ¡ {task_id} æ‰§è¡Œå¤±è´¥: {e}")
        
        # 7. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        print(f"\nğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡:")
        generate_real_cluster_test_report()
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        task_statistics['errors'].append(f"æµ‹è¯•è¿‡ç¨‹é”™è¯¯: {e}")
        return False


def generate_real_cluster_test_report():
    """ç”ŸæˆçœŸå®é›†ç¾¤æµ‹è¯•æŠ¥å‘Š"""
    print(f"\nğŸ“‹ ä»»åŠ¡ç»Ÿè®¡:")
    print(f"  â€¢ æ€»æäº¤ä»»åŠ¡: {task_statistics['total_submitted']}ä¸ª")
    print(f"  â€¢ æ€»å®Œæˆä»»åŠ¡: {task_statistics['total_completed']}ä¸ª")
    print(f"  â€¢ é”™è¯¯ä»»åŠ¡æ•°: {len(task_statistics['errors'])}ä¸ª")
    
    print(f"\nğŸ“‹ é›†ç¾¤åˆ†å¸ƒ:")
    total_distributed = sum(task_statistics['cluster_distribution'].values())
    for cluster, count in task_statistics['cluster_distribution'].items():
        percentage = (count / total_distributed * 100) if total_distributed > 0 else 0
        print(f"  â€¢ {cluster}: {count}ä¸ªä»»åŠ¡ ({percentage:.1f}%)")
    
    # åˆ†æè´Ÿè½½å‡è¡¡æ•ˆæœ
    print(f"\nğŸ“‹ è´Ÿè½½å‡è¡¡åˆ†æ:")
    if len(task_statistics['cluster_distribution']) > 1:
        counts = list(task_statistics['cluster_distribution'].values())
        max_count = max(counts)
        min_count = min(counts)
        balance_ratio = min_count / max_count if max_count > 0 else 0
        
        print(f"  âœ… å®ç°äº†è·¨é›†ç¾¤è´Ÿè½½å‡è¡¡")
        print(f"     â€¢ ä¸åŒé›†ç¾¤éƒ½æœ‰ä»»åŠ¡æ‰§è¡Œ")
        print(f"     â€¢ è´Ÿè½½å‡è¡¡æ¯”ç‡: {balance_ratio:.2f} (è¶Šæ¥è¿‘1è¶Šå‡è¡¡)")
    else:
        print(f"  âš ï¸  ä»»åŠ¡ä¸»è¦åœ¨å•ä¸ªé›†ç¾¤æ‰§è¡Œ")
        print(f"     â€¢ æœªå……åˆ†åˆ©ç”¨å¤šé›†ç¾¤èµ„æº")
    
    # é”™è¯¯åˆ†æ
    if task_statistics['errors']:
        print(f"\nğŸ“‹ é”™è¯¯åˆ†æ:")
        for error in task_statistics['errors'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
            print(f"  â€¢ {error}")
        if len(task_statistics['errors']) > 5:
            print(f"  ... è¿˜æœ‰ {len(task_statistics['errors']) - 5} ä¸ªé”™è¯¯")


def analyze_cluster_capabilities():
    """åˆ†æé›†ç¾¤èƒ½åŠ›"""
    print("\n" + "=" * 80)
    print("ğŸ§  é›†ç¾¤èƒ½åŠ›åˆ†æ")
    print("=" * 80)
    
    print(f"\nğŸ“‹ é›†ç¾¤é…ç½®:")
    print(f"  â€¢ centosé›†ç¾¤:")
    print(f"    - åœ°å€: 192.168.5.7:32546")
    print(f"    - æƒé‡: 1.0")
    print(f"    - åå¥½: å¦")
    print(f"    - æ ‡ç­¾: linux, x86_64")
    
    print(f"\n  â€¢ macé›†ç¾¤:")
    print(f"    - åœ°å€: 192.168.5.2:32546")
    print(f"    - æƒé‡: 1.2")
    print(f"    - åå¥½: æ˜¯")
    print(f"    - æ ‡ç­¾: macos, arm64")
    
    print(f"\nğŸ“‹ è´Ÿè½½å‡è¡¡ç­–ç•¥:")
    print(f"  1. è¯„åˆ†è®¡ç®—:")
    print(f"     â€¢ åŸºç¡€è¯„åˆ† = å¯ç”¨CPU Ã— é›†ç¾¤æƒé‡")
    print(f"     â€¢ GPUèµ„æºåŠ æˆ = å¯ç”¨GPU Ã— 5")
    print(f"     â€¢ åå¥½é›†ç¾¤åŠ æˆ = 1.2")
    print(f"     â€¢ è´Ÿè½½å‡è¡¡å› å­ = 1.0 - CPUä½¿ç”¨ç‡")
    print(f"     â€¢ æœ€ç»ˆè¯„åˆ† = (åŸºç¡€è¯„åˆ† + GPUåŠ æˆ) Ã— åå¥½åŠ æˆ Ã— è´Ÿè½½å‡è¡¡å› å­")
    
    print(f"\n  2. è°ƒåº¦å†³ç­–:")
    print(f"     â€¢ æœªæŒ‡å®šé›†ç¾¤çš„ä»»åŠ¡ä½¿ç”¨è´Ÿè½½å‡è¡¡ç­–ç•¥")
    print(f"     â€¢ æ ¹æ®è¯„åˆ†é€‰æ‹©æœ€ä½³é›†ç¾¤")
    print(f"     â€¢ æ”¯æŒMACé›†ç¾¤ç‰¹æ®Šèµ„æºå¤„ç†")


def main():
    # åˆ†æé›†ç¾¤èƒ½åŠ›
    analyze_cluster_capabilities()
    
    # è¿è¡ŒçœŸå®é›†ç¾¤è¿æ¥æµ‹è¯•
    success = test_real_cluster_load_balancing()
    
    print("\n" + "=" * 80)
    print("ğŸ æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    
    if success:
        if len(task_statistics['cluster_distribution']) > 1:
            print(f"âœ… è´Ÿè½½å‡è¡¡ç­–ç•¥éªŒè¯æˆåŠŸ")
            print(f"   â€¢ ä»»åŠ¡è¢«åˆ†æ•£åˆ°å¤šä¸ªé›†ç¾¤æ‰§è¡Œ")
            print(f"   â€¢ å®ç°äº†è·¨é›†ç¾¤è´Ÿè½½å‡è¡¡")
        else:
            print(f"âš ï¸  è´Ÿè½½å‡è¡¡ç­–ç•¥æœ‰å¾…æ”¹è¿›")
            print(f"   â€¢ ä»»åŠ¡ä¸»è¦åœ¨å•ä¸ªé›†ç¾¤æ‰§è¡Œ")
            print(f"   â€¢ æœªå……åˆ†åˆ©ç”¨å¤šé›†ç¾¤èµ„æº")
    else:
        print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥")
        print(f"   â€¢ è¯·æ£€æŸ¥é›†ç¾¤è¿æ¥çŠ¶æ€")
        print(f"   â€¢ ç¡®è®¤é›†ç¾¤é…ç½®æ­£ç¡®")
    
    print(f"\nğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:")
    print(f"   â€¢ æ€»æäº¤ä»»åŠ¡: {task_statistics['total_submitted']}ä¸ª")
    print(f"   â€¢ æ€»å®Œæˆä»»åŠ¡: {task_statistics['total_completed']}ä¸ª")
    for cluster, count in task_statistics['cluster_distribution'].items():
        print(f"   â€¢ {cluster}: {count}ä¸ªä»»åŠ¡")


if __name__ == "__main__":
    # å¯¼å…¥threadingæ¨¡å—
    import threading
    main()