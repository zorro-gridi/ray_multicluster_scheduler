#!/usr/bin/env python3
"""
çœŸå®é›†ç¾¤è¿æ¥è´Ÿè½½å‡è¡¡ç­–ç•¥éªŒè¯æµ‹è¯•
ä¸“æ³¨äºéªŒè¯ç­–ç•¥å†³ç­–è€Œä¸æ‰§è¡Œå®é™…ä»»åŠ¡
"""

import sys
import os
import time
from collections import defaultdict
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)) + '/..')

from ray_multicluster_scheduler.app.client_api.unified_scheduler import (
    UnifiedScheduler,
    initialize_scheduler_environment
)
from ray_multicluster_scheduler.scheduler.policy.policy_engine import PolicyEngine
from ray_multicluster_scheduler.common.model import TaskDescription


def test_load_balancing_strategy_with_real_clusters():
    """æµ‹è¯•ä½¿ç”¨çœŸå®é›†ç¾¤è¿æ¥çš„è´Ÿè½½å‡è¡¡ç­–ç•¥"""
    print("=" * 80)
    print("ğŸ” çœŸå®é›†ç¾¤è¿æ¥è´Ÿè½½å‡è¡¡ç­–ç•¥éªŒè¯æµ‹è¯•")
    print("=" * 80)

    try:
        # 1. åˆå§‹åŒ–è°ƒåº¦ç¯å¢ƒ
        print("ğŸ”§ åˆå§‹åŒ–è°ƒåº¦ç¯å¢ƒ...")
        task_lifecycle_manager = initialize_scheduler_environment()
        print("âœ… è°ƒåº¦ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")

        # 2. è·å–é›†ç¾¤ç›‘è§†å™¨
        cluster_monitor = task_lifecycle_manager.cluster_monitor

        # 3. åˆ·æ–°é›†ç¾¤çŠ¶æ€
        print("ğŸ”„ åˆ·æ–°é›†ç¾¤çŠ¶æ€...")
        cluster_monitor.refresh_resource_snapshots(force=True)
        print("âœ… é›†ç¾¤çŠ¶æ€åˆ·æ–°å®Œæˆ")

        # 4. è·å–é›†ç¾¤ä¿¡æ¯
        print("ğŸ“‹ è·å–é›†ç¾¤ä¿¡æ¯...")
        cluster_info = cluster_monitor.get_all_cluster_info()

        print(f"\nğŸ“Š é›†ç¾¤çŠ¶æ€ä¿¡æ¯:")
        cluster_snapshots = {}
        cluster_metadata = {}

        for cluster_name, info in cluster_info.items():
            if info and 'snapshot' in info and info['snapshot']:
                snapshot = info['snapshot']
                metadata = info['metadata']
                cluster_snapshots[cluster_name] = snapshot
                cluster_metadata[cluster_name] = metadata

                cpu_available = snapshot.available_resources.get("CPU", 0)
                cpu_total = snapshot.total_resources.get("CPU", 0)
                gpu_available = snapshot.available_resources.get("GPU", 0)
                gpu_total = snapshot.total_resources.get("GPU", 0)

                print(f"  â€¢ {cluster_name}: CPU={cpu_available}/{cpu_total}, GPU={gpu_available}/{gpu_total}")
            else:
                print(f"  â€¢ {cluster_name}: æ— æ³•è·å–èµ„æºä¿¡æ¯")

        # 5. åˆ›å»ºç­–ç•¥å¼•æ“
        print("ğŸ”§ åˆ›å»ºç­–ç•¥å¼•æ“...")
        policy_engine = PolicyEngine(cluster_monitor)
        policy_engine.update_cluster_metadata(cluster_metadata)
        print("âœ… ç­–ç•¥å¼•æ“åˆ›å»ºå®Œæˆ")

        # 6. æ¨¡æ‹Ÿä»»åŠ¡è°ƒåº¦å†³ç­–
        print(f"\nğŸš€ æ¨¡æ‹Ÿä»»åŠ¡è°ƒåº¦å†³ç­–...")
        cluster_distribution = defaultdict(int)

        # æäº¤20ä¸ªä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡éœ€è¦2ä¸ªCPUï¼Œä¸æŒ‡å®šé›†ç¾¤
        for i in range(20):
            task_desc = TaskDescription(
                task_id=f"lb_test_task_{i}",
                name=f"è´Ÿè½½å‡è¡¡æµ‹è¯•ä»»åŠ¡{i}",
                func_or_class=lambda: None,
                args=(),
                kwargs={},
                resource_requirements={"CPU": 2.0},
                tags=["test", "load_balance"],
                preferred_cluster=None  # ä¸æŒ‡å®šé›†ç¾¤ï¼Œä½¿ç”¨è´Ÿè½½å‡è¡¡
            )

            # è®©ç­–ç•¥å¼•æ“åšè°ƒåº¦å†³ç­–
            decision = policy_engine.schedule(task_desc, cluster_snapshots)

            if decision and decision.cluster_name:
                cluster_distribution[decision.cluster_name] += 1
                print(f"    ä»»åŠ¡ {i}: è°ƒåº¦åˆ° {decision.cluster_name} - {decision.reason}")
            else:
                print(f"    ä»»åŠ¡ {i}: æ— æ³•è°ƒåº¦")

        # 7. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        print(f"\nğŸ“Š è°ƒåº¦å†³ç­–ç»Ÿè®¡:")
        total_scheduled = sum(cluster_distribution.values())
        for cluster_name, count in cluster_distribution.items():
            percentage = (count / total_scheduled * 100) if total_scheduled > 0 else 0
            print(f"  â€¢ {cluster_name}: {count}ä¸ªä»»åŠ¡ ({percentage:.1f}%)")

        # 8. åˆ†æè´Ÿè½½å‡è¡¡æ•ˆæœ
        print(f"\nğŸ“‹ è´Ÿè½½å‡è¡¡æ•ˆæœåˆ†æ:")
        if len(cluster_distribution) > 1:
            counts = list(cluster_distribution.values())
            max_count = max(counts)
            min_count = min(counts)
            balance_ratio = min_count / max_count if max_count > 0 else 0

            print(f"  âœ… å®ç°äº†è·¨é›†ç¾¤è´Ÿè½½å‡è¡¡")
            print(f"     â€¢ ä¸åŒé›†ç¾¤éƒ½æœ‰ä»»åŠ¡è¢«è°ƒåº¦")
            print(f"     â€¢ è´Ÿè½½å‡è¡¡æ¯”ç‡: {balance_ratio:.2f} (è¶Šæ¥è¿‘1è¶Šå‡è¡¡)")
        else:
            print(f"  âš ï¸  ä»»åŠ¡ä¸»è¦åœ¨å•ä¸ªé›†ç¾¤è°ƒåº¦")
            print(f"     â€¢ æœªå……åˆ†åˆ©ç”¨å¤šé›†ç¾¤èµ„æº")

        return cluster_distribution

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    # è¿è¡ŒçœŸå®é›†ç¾¤è¿æ¥è´Ÿè½½å‡è¡¡ç­–ç•¥æµ‹è¯•
    cluster_dist = test_load_balancing_strategy_with_real_clusters()

    if cluster_dist:
        print("\n" + "=" * 80)
        print("ğŸ æµ‹è¯•æ€»ç»“")
        print("=" * 80)

        if len(cluster_dist) > 1:
            print(f"âœ… è´Ÿè½½å‡è¡¡ç­–ç•¥éªŒè¯æˆåŠŸ")
            print(f"   â€¢ ä»»åŠ¡è¢«åˆ†æ•£åˆ°å¤šä¸ªé›†ç¾¤")
            print(f"   â€¢ å®ç°äº†è·¨é›†ç¾¤è´Ÿè½½å‡è¡¡")
        else:
            print(f"âš ï¸  è´Ÿè½½å‡è¡¡ç­–ç•¥æœ‰å¾…æ”¹è¿›")
            print(f"   â€¢ ä»»åŠ¡ä¸»è¦åœ¨å•ä¸ªé›†ç¾¤è°ƒåº¦")
            print(f"   â€¢ æœªå……åˆ†åˆ©ç”¨å¤šé›†ç¾¤èµ„æº")

        print(f"\nğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:")
        total_scheduled = sum(cluster_dist.values())
        for cluster, count in cluster_dist.items():
            percentage = (count / total_scheduled * 100) if total_scheduled > 0 else 0
            print(f"   â€¢ {cluster}: {count}ä¸ªä»»åŠ¡ ({percentage:.1f}%)")
    else:
        print("\n" + "=" * 80)
        print("âŒ æµ‹è¯•å¤±è´¥")
        print("=" * 80)
        print(f"   â€¢ è¯·æ£€æŸ¥é›†ç¾¤è¿æ¥çŠ¶æ€")
        print(f"   â€¢ ç¡®è®¤é›†ç¾¤é…ç½®æ­£ç¡®")


if __name__ == "__main__":
    main()