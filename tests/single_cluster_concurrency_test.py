#!/usr/bin/env python3
"""
å•é›†ç¾¤å¹¶å‘è°ƒåº¦é—®é¢˜æµ‹è¯•ç”¨ä¾‹
éªŒè¯å½“æäº¤çš„å¹¶å‘ä»»åŠ¡æ•°é‡å¤§äºä»»ä½•å•ä¸€é›†ç¾¤çš„æœ€å¤§å¯ç”¨å¹¶å‘é‡æ—¶ï¼Œ
ç³»ç»Ÿæ˜¯å¦çœŸçš„åªæœ‰ä¸€ä¸ªé›†ç¾¤åœ¨è¿›è¡Œå¹¶å‘è°ƒåº¦
"""

import sys
import os
import time
from collections import defaultdict
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)) + '/..')

from ray_multicluster_scheduler.common.model import TaskDescription, ResourceSnapshot, ClusterMetadata
from ray_multicluster_scheduler.scheduler.policy.policy_engine import PolicyEngine


def single_cluster_concurrency_test():
    """å•é›†ç¾¤å¹¶å‘è°ƒåº¦é—®é¢˜æµ‹è¯•"""
    print("=" * 80)
    print("ğŸ” å•é›†ç¾¤å¹¶å‘è°ƒåº¦é—®é¢˜æµ‹è¯•")
    print("=" * 80)

    # æ¨¡æ‹Ÿé›†ç¾¤é…ç½® - macä¸ºé¦–é€‰é›†ç¾¤
    cluster_configs = {
        "centos": ClusterMetadata(
            name="centos",
            head_address="192.168.5.7:32546",
            dashboard="http://192.168.5.7:31591",
            prefer=False,
            weight=1.0,
            runtime_env={
                "conda": "ts",
                "env_vars": {"home_dir": "/home/zorro"}
            },
            tags=["linux", "x86_64"]
        ),
        "mac": ClusterMetadata(
            name="mac",
            head_address="192.168.5.2:32546",
            dashboard="http://192.168.5.2:8265",
            prefer=True,
            weight=1.2,
            runtime_env={
                "conda": "k8s",
                "env_vars": {"home_dir": "/Users/zorro"}
            },
            tags=["macos", "arm64"]
        )
    }

    # åˆ›å»ºç­–ç•¥å¼•æ“å¹¶æ›´æ–°é›†ç¾¤å…ƒæ•°æ®
    policy_engine = PolicyEngine()
    policy_engine.update_cluster_metadata(cluster_configs)

    # æµ‹è¯•åœºæ™¯: æäº¤è¶…è¿‡ä»»ä¸€é›†ç¾¤å®¹é‡çš„ä»»åŠ¡ï¼Œè§‚å¯Ÿè°ƒåº¦åˆ†å¸ƒ
    print(f"\nğŸ“‹ æµ‹è¯•åœºæ™¯: æäº¤è¶…è¿‡ä»»ä¸€é›†ç¾¤å®¹é‡çš„ä»»åŠ¡")
    print(f"   centosé›†ç¾¤å®¹é‡: 16 CPU")
    print(f"   macé›†ç¾¤å®¹é‡: 8 CPU")
    print(f"   æäº¤20ä¸ªä»»åŠ¡ï¼ˆè¶…è¿‡macé›†ç¾¤å®¹é‡ï¼Œä½†å°äºcentosé›†ç¾¤å®¹é‡ï¼‰")

    # æ¨¡æ‹Ÿå……è¶³çš„èµ„æºæƒ…å†µ
    current_time = time.time()
    cluster_snapshots = {
        "centos": ResourceSnapshot(
            cluster_name="centos",
            total_resources={"CPU": 16.0, "GPU": 0},
            available_resources={"CPU": 16.0, "GPU": 0},
            node_count=5,
            timestamp=current_time
        ),
        "mac": ResourceSnapshot(
            cluster_name="mac",
            total_resources={"CPU": 8.0, "GPU": 0},
            available_resources={"CPU": 8.0, "GPU": 0},
            node_count=1,
            timestamp=current_time
        )
    }

    # ç»Ÿè®¡å˜é‡
    cluster_distribution = defaultdict(int)
    queued_tasks = 0

    # æäº¤20ä¸ªä»»åŠ¡ï¼Œä¸æŒ‡å®šé›†ç¾¤ï¼ˆä½¿ç”¨è´Ÿè½½å‡è¡¡ï¼‰
    print(f"\nğŸš€ æäº¤20ä¸ªä»»åŠ¡ï¼ˆä¸æŒ‡å®šé›†ç¾¤ï¼‰:")
    for i in range(20):
        task_desc = TaskDescription(
            task_id=f"load_balance_task_{i}",
            name=f"load_balance_task_{i}",
            func_or_class=lambda: None,
            args=(),
            kwargs={},
            resource_requirements={"CPU": 1.0},
            tags=["test", "load_balance"],
            preferred_cluster=None  # ä¸æŒ‡å®šé›†ç¾¤ï¼Œä½¿ç”¨è´Ÿè½½å‡è¡¡
        )

        # è®©ç­–ç•¥å¼•æ“åšè°ƒåº¦å†³ç­–
        decision = policy_engine.schedule(task_desc, cluster_snapshots)

        if decision and decision.cluster_name:
            cluster_distribution[decision.cluster_name] += 1
            print(f"    ä»»åŠ¡ {i}: è°ƒåº¦åˆ° {decision.cluster_name} - {decision.reason}")
        else:
            queued_tasks += 1
            print(f"    ä»»åŠ¡ {i}: è¿›å…¥é˜Ÿåˆ—ç­‰å¾…")

    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡:")
    generate_single_cluster_test_report(cluster_distribution, queued_tasks)

    return cluster_distribution, queued_tasks


def test_preferred_cluster_behavior():
    """æµ‹è¯•æŒ‡å®šé›†ç¾¤çš„è¡Œä¸º"""
    print(f"\n" + "=" * 80)
    print("ğŸ” æŒ‡å®šé›†ç¾¤è¡Œä¸ºæµ‹è¯•")
    print("=" * 80)

    # æ¨¡æ‹Ÿé›†ç¾¤é…ç½®
    cluster_configs = {
        "centos": ClusterMetadata(
            name="centos",
            head_address="192.168.5.7:32546",
            dashboard="http://192.168.5.7:31591",
            prefer=False,
            weight=1.0,
            runtime_env={
                "conda": "ts",
                "env_vars": {"home_dir": "/home/zorro"}
            },
            tags=["linux", "x86_64"]
        ),
        "mac": ClusterMetadata(
            name="mac",
            head_address="192.168.5.2:32546",
            dashboard="http://192.168.5.2:8265",
            prefer=True,
            weight=1.2,
            runtime_env={
                "conda": "k8s",
                "env_vars": {"home_dir": "/Users/zorro"}
            },
            tags=["macos", "arm64"]
        )
    }

    # åˆ›å»ºç­–ç•¥å¼•æ“å¹¶æ›´æ–°é›†ç¾¤å…ƒæ•°æ®
    policy_engine = PolicyEngine()
    policy_engine.update_cluster_metadata(cluster_configs)

    # æ¨¡æ‹Ÿèµ„æºå……è¶³çš„æƒ…å†µ
    current_time = time.time()
    cluster_snapshots = {
        "centos": ResourceSnapshot(
            cluster_name="centos",
            total_resources={"CPU": 16.0, "GPU": 0},
            available_resources={"CPU": 16.0, "GPU": 0},
            node_count=5,
            timestamp=current_time
        ),
        "mac": ResourceSnapshot(
            cluster_name="mac",
            total_resources={"CPU": 8.0, "GPU": 0},
            available_resources={"CPU": 8.0, "GPU": 0},
            node_count=1,
            timestamp=current_time
        )
    }

    # ç»Ÿè®¡å˜é‡
    cluster_distribution = defaultdict(int)
    queued_tasks = 0

    # æäº¤è¶…è¿‡macé›†ç¾¤å®¹é‡çš„ä»»åŠ¡ï¼Œä½†æŒ‡å®šåˆ°macé›†ç¾¤
    print(f"\nğŸš€ æäº¤12ä¸ªä»»åŠ¡åˆ°macé›†ç¾¤ï¼ˆè¶…è¿‡å…¶8ä¸ªCPUå®¹é‡ï¼‰:")
    for i in range(12):
        task_desc = TaskDescription(
            task_id=f"mac_preferred_task_{i}",
            name=f"mac_preferred_task_{i}",
            func_or_class=lambda: None,
            args=(),
            kwargs={},
            resource_requirements={"CPU": 1.0},
            tags=["test", "mac_preferred"],
            preferred_cluster="mac"  # æŒ‡å®šåˆ°macé›†ç¾¤
        )

        # è®©ç­–ç•¥å¼•æ“åšè°ƒåº¦å†³ç­–
        decision = policy_engine.schedule(task_desc, cluster_snapshots)

        if decision and decision.cluster_name:
            cluster_distribution[decision.cluster_name] += 1
            print(f"    ä»»åŠ¡ {i}: è°ƒåº¦åˆ° {decision.cluster_name}")
        else:
            queued_tasks += 1
            print(f"    ä»»åŠ¡ {i}: è¿›å…¥é˜Ÿåˆ—ç­‰å¾…")

    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    print(f"\nğŸ“Š æŒ‡å®šé›†ç¾¤æµ‹è¯•ç»“æœç»Ÿè®¡:")
    generate_preferred_cluster_test_report(cluster_distribution, queued_tasks)

    return cluster_distribution, queued_tasks


def generate_single_cluster_test_report(cluster_distribution, queued_tasks):
    """ç”Ÿæˆå•é›†ç¾¤æµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ å•é›†ç¾¤å¹¶å‘è°ƒåº¦æµ‹è¯•æŠ¥å‘Š")
    print("=" * 60)

    total_scheduled = sum(cluster_distribution.values())
    total_tasks = total_scheduled + queued_tasks

    print(f"  æ€»æäº¤ä»»åŠ¡æ•°: {total_tasks}")
    print(f"  æˆåŠŸè°ƒåº¦ä»»åŠ¡æ•°: {total_scheduled}")
    print(f"  é˜Ÿåˆ—ç­‰å¾…ä»»åŠ¡æ•°: {queued_tasks}")

    print(f"\n  é›†ç¾¤è°ƒåº¦åˆ†å¸ƒ:")
    for cluster, count in cluster_distribution.items():
        percentage = (count / total_scheduled * 100) if total_scheduled > 0 else 0
        print(f"    {cluster}: {count} ä¸ªä»»åŠ¡ ({percentage:.1f}%)")

    # åˆ†ææ˜¯å¦å­˜åœ¨å•é›†ç¾¤è°ƒåº¦é—®é¢˜
    if len(cluster_distribution) == 1:
        print(f"\n  âš ï¸  å‘ç°å•é›†ç¾¤è°ƒåº¦é—®é¢˜:")
        print(f"     æ‰€æœ‰ä»»åŠ¡éƒ½è¢«è°ƒåº¦åˆ°åŒä¸€ä¸ªé›†ç¾¤: {list(cluster_distribution.keys())[0]}")
        print(f"     ç†è®ºä¸Šåº”è¯¥æ ¹æ®è´Ÿè½½å‡è¡¡ç®—æ³•åˆ†å¸ƒåˆ°å¤šä¸ªé›†ç¾¤")
    elif len(cluster_distribution) > 1:
        print(f"\n  âœ… è´Ÿè½½å‡è¡¡æ­£å¸¸:")
        print(f"     ä»»åŠ¡è¢«åˆ†å¸ƒåˆ° {len(cluster_distribution)} ä¸ªé›†ç¾¤")
        print(f"     ç¬¦åˆè´Ÿè½½å‡è¡¡è°ƒåº¦é¢„æœŸ")
    else:
        print(f"\n  âš ï¸  æ— ä»»åŠ¡è¢«æˆåŠŸè°ƒåº¦")


def generate_preferred_cluster_test_report(cluster_distribution, queued_tasks):
    """ç”ŸæˆæŒ‡å®šé›†ç¾¤æµ‹è¯•æŠ¥å‘Š"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ æŒ‡å®šé›†ç¾¤è¡Œä¸ºæµ‹è¯•æŠ¥å‘Š")
    print("=" * 60)

    total_scheduled = sum(cluster_distribution.values())
    total_tasks = total_scheduled + queued_tasks

    print(f"  æ€»æäº¤ä»»åŠ¡æ•°: {total_tasks}")
    print(f"  æˆåŠŸè°ƒåº¦ä»»åŠ¡æ•°: {total_scheduled}")
    print(f"  é˜Ÿåˆ—ç­‰å¾…ä»»åŠ¡æ•°: {queued_tasks}")

    print(f"\n  é›†ç¾¤è°ƒåº¦åˆ†å¸ƒ:")
    for cluster, count in cluster_distribution.items():
        percentage = (count / total_scheduled * 100) if total_scheduled > 0 else 0
        print(f"    {cluster}: {count} ä¸ªä»»åŠ¡ ({percentage:.1f}%)")

    # åˆ†ææŒ‡å®šé›†ç¾¤è¡Œä¸º
    if len(cluster_distribution) == 1 and "mac" in cluster_distribution:
        mac_scheduled = cluster_distribution["mac"]
        if mac_scheduled <= 8 and queued_tasks > 0:
            print(f"\n  âœ… æŒ‡å®šé›†ç¾¤è¡Œä¸ºæ­£å¸¸:")
            print(f"     æŒ‡å®šé›†ç¾¤(mac)æœ€å¤šè°ƒåº¦8ä¸ªä»»åŠ¡")
            print(f"     è¶…å‡ºå®¹é‡çš„ä»»åŠ¡({queued_tasks}ä¸ª)è¿›å…¥é˜Ÿåˆ—ç­‰å¾…")
        elif mac_scheduled > 8:
            print(f"\n  âš ï¸  æŒ‡å®šé›†ç¾¤è¡Œä¸ºå¼‚å¸¸:")
            print(f"     æŒ‡å®šé›†ç¾¤(mac)è°ƒåº¦äº†è¶…è¿‡å…¶å®¹é‡çš„ä»»åŠ¡")
        else:
            print(f"\n  âœ… æŒ‡å®šé›†ç¾¤è¡Œä¸ºæ­£å¸¸:")
            print(f"     æ‰€æœ‰ä»»åŠ¡éƒ½åœ¨æŒ‡å®šé›†ç¾¤æ‰§è¡Œ")
    else:
        print(f"\n  âš ï¸  æŒ‡å®šé›†ç¾¤è¡Œä¸ºå¼‚å¸¸:")
        print(f"     ä»»åŠ¡è¢«è°ƒåº¦åˆ°äº†éæŒ‡å®šé›†ç¾¤")


def analyze_scheduling_algorithm():
    """åˆ†æè°ƒåº¦ç®—æ³•"""
    print("\n" + "=" * 80)
    print("ğŸ§  è°ƒåº¦ç®—æ³•åˆ†æ")
    print("=" * 80)

    print(f"\nğŸ“‹ è´Ÿè½½å‡è¡¡è°ƒåº¦é€»è¾‘:")
    print(f"  1. æœªæŒ‡å®šé›†ç¾¤çš„ä»»åŠ¡ä¼šç»å†ä»¥ä¸‹å†³ç­–è¿‡ç¨‹:")
    print(f"     â€¢ æ”¶é›†æ‰€æœ‰å¥åº·é›†ç¾¤çš„èµ„æºå¿«ç…§")
    print(f"     â€¢ è®¡ç®—æ¯ä¸ªé›†ç¾¤çš„è¯„åˆ†")
    print(f"     â€¢ è¯„åˆ†å› ç´ åŒ…æ‹¬: å¯ç”¨èµ„æºã€é›†ç¾¤æƒé‡ã€åå¥½è®¾ç½®ã€è´Ÿè½½å‡è¡¡å› å­")
    print(f"     â€¢ é€‰æ‹©è¯„åˆ†æœ€é«˜çš„é›†ç¾¤è¿›è¡Œè°ƒåº¦")

    print(f"\n  2. è¯„åˆ†è®¡ç®—å…¬å¼:")
    print(f"     â€¢ åŸºç¡€è¯„åˆ† = å¯ç”¨CPU Ã— é›†ç¾¤æƒé‡")
    print(f"     â€¢ GPUèµ„æºåŠ æˆ = å¯ç”¨GPU Ã— 5ï¼ˆGPUæ›´å®è´µï¼‰")
    print(f"     â€¢ åå¥½é›†ç¾¤åŠ æˆ = 1.2ï¼ˆå¦‚æœæ˜¯åå¥½é›†ç¾¤ï¼‰")
    print(f"     â€¢ è´Ÿè½½å‡è¡¡å› å­ = 1.0 - CPUä½¿ç”¨ç‡")
    print(f"     â€¢ æœ€ç»ˆè¯„åˆ† = (åŸºç¡€è¯„åˆ† + GPUåŠ æˆ) Ã— åå¥½åŠ æˆ Ã— è´Ÿè½½å‡è¡¡å› å­")

    print(f"\n  3. è°ƒåº¦å†³ç­–ä¼˜å…ˆçº§:")
    print(f"     â€¢ é¦–é€‰é›†ç¾¤æŒ‡å®š > è´Ÿè½½å‡è¡¡")
    print(f"     â€¢ èµ„æºé˜ˆå€¼æ£€æŸ¥ > é›†ç¾¤è¯„åˆ†")
    print(f"     â€¢ é›†ç¾¤å¥åº·çŠ¶æ€ > æ‰€æœ‰å…¶ä»–å› ç´ ")


def answer_user_observation():
    """å›ç­”ç”¨æˆ·è§‚å¯Ÿåˆ°çš„é—®é¢˜"""
    print("\n" + "=" * 80)
    print("ğŸ¯ å›ç­”ç”¨æˆ·è§‚å¯Ÿåˆ°çš„é—®é¢˜")
    print("=" * 80)

    print(f"\né—®é¢˜: ç”¨æˆ·é€šè¿‡å®é™…ä»»åŠ¡æµ‹è¯•å‘ç°ï¼Œå³ä½¿ä¸æŒ‡å®šä¼˜å…ˆè°ƒåº¦é›†ç¾¤æ—¶ï¼Œ")
    print(f"      å½“æäº¤çš„å¹¶å‘ä»»åŠ¡æ•°é‡å¤§äºä»»ä½•å•ä¸€é›†ç¾¤çš„æœ€å¤§å¯ç”¨å¹¶å‘é‡æ—¶ï¼Œ")
    print(f"      ä¹Ÿåªæœ‰ä¸€ä¸ªé›†ç¾¤åœ¨è¿›è¡Œå¹¶å‘è°ƒåº¦ã€‚")

    print(f"\nåˆ†æå¯èƒ½çš„åŸå› :")
    print(f"  1. è´Ÿè½½å‡è¡¡ç®—æ³•åå‘æ€§:")
    print(f"     â€¢ macé›†ç¾¤è®¾ç½®äº†prefer=Trueï¼Œæœ‰é¢å¤–çš„åå¥½åŠ æˆ(1.2å€)")
    print(f"     â€¢ macé›†ç¾¤æƒé‡ä¸º1.2ï¼Œæ¯”centosçš„1.0æ›´é«˜")
    print(f"     â€¢ å³ä½¿macé›†ç¾¤å®¹é‡è¾ƒå°ï¼Œä½†ç»¼åˆè¯„åˆ†å¯èƒ½æ›´é«˜")

    print(f"\n  2. èµ„æºåˆ©ç”¨ç‡å½±å“:")
    print(f"     â€¢ è´Ÿè½½å‡è¡¡å› å­ = 1.0 - CPUä½¿ç”¨ç‡")
    print(f"     â€¢ å¦‚æœä¸€ä¸ªé›†ç¾¤åˆšå¼€å§‹è°ƒåº¦ä»»åŠ¡ï¼Œå…¶è´Ÿè½½å‡è¡¡å› å­è¾ƒé«˜")
    print(f"     â€¢ ç®—æ³•å¯èƒ½å€¾å‘äºç»§ç»­å‘åŒä¸€é›†ç¾¤è°ƒåº¦ä»¥ä¿æŒè¿ç»­æ€§")

    print(f"\n  3. è°ƒåº¦æ‰¹æ¬¡æ•ˆåº”:")
    print(f"     â€¢ åœ¨çŸ­æ—¶é—´å†…æäº¤å¤§é‡ä»»åŠ¡")
    print(f"     â€¢ ç³»ç»Ÿå¯èƒ½è¿˜æœªåŠæ—¶æ›´æ–°èµ„æºå¿«ç…§")
    print(f"     â€¢ å¯¼è‡´è¿ç»­ä»»åŠ¡è¢«è°ƒåº¦åˆ°åŒä¸€é›†ç¾¤")

    print(f"\néªŒè¯å»ºè®®:")
    print(f"  â€¢ æ£€æŸ¥é›†ç¾¤çš„preferè®¾ç½®å’Œæƒé‡é…ç½®")
    print(f"  â€¢ éªŒè¯è´Ÿè½½å‡è¡¡ç®—æ³•çš„å®é™…è¯„åˆ†è®¡ç®—")
    print(f"  â€¢ è§‚å¯Ÿé•¿æ—¶é—´è·¨åº¦å†…çš„ä»»åŠ¡åˆ†å¸ƒæƒ…å†µ")


if __name__ == "__main__":
    # è¿è¡Œå•é›†ç¾¤å¹¶å‘è°ƒåº¦æµ‹è¯•
    lb_distribution, lb_queued = single_cluster_concurrency_test()

    # è¿è¡ŒæŒ‡å®šé›†ç¾¤è¡Œä¸ºæµ‹è¯•
    pref_distribution, pref_queued = test_preferred_cluster_behavior()

    # åˆ†æè°ƒåº¦ç®—æ³•
    analyze_scheduling_algorithm()

    # å›ç­”ç”¨æˆ·è§‚å¯Ÿåˆ°çš„é—®é¢˜
    answer_user_observation()

    print("\n" + "=" * 80)
    print("ğŸ‰ å•é›†ç¾¤å¹¶å‘è°ƒåº¦é—®é¢˜æµ‹è¯•å®Œæˆ!")
    print("=" * 80)