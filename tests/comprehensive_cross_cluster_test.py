#!/usr/bin/env python3
"""
ç»¼åˆè·¨é›†ç¾¤è°ƒåº¦æµ‹è¯•ç”¨ä¾‹
å±•ç¤ºå¹¶å‘ä»»åŠ¡åœ¨æ‰€æœ‰ç³»ç»Ÿå¯ç”¨é›†ç¾¤ä¹‹é—´çš„è´Ÿè½½åˆ†é…å’Œè°ƒåº¦æ‰§è¡Œæƒ…å†µï¼Œå¹¶æä¾›ç»Ÿè®¡æ•°æ®
"""

import sys
import os
import time
import threading
from collections import defaultdict
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)) + '/..')

from ray_multicluster_scheduler.app.client_api.unified_scheduler import (
    UnifiedScheduler,
    initialize_scheduler_environment,
    submit_task
)


# ç”¨äºæ”¶é›†ç»Ÿè®¡æ•°æ®çš„å…¨å±€å˜é‡
task_statistics = {
    'total_submitted': 0,
    'total_completed': 0,
    'cluster_distribution': defaultdict(int),
    'task_results': [],
    'errors': []
}
stats_lock = threading.Lock()


def test_task_with_stats(task_id, task_name, duration=1):
    """å¸¦ç»Ÿè®¡ä¿¡æ¯çš„æµ‹è¯•ä»»åŠ¡å‡½æ•°"""
    import time
    import threading

    start_time = time.time()
    print(f"[{threading.current_thread().name}] ä»»åŠ¡ {task_id} ({task_name}) å¼€å§‹æ‰§è¡Œ")
    time.sleep(duration)
    end_time = time.time()

    result = {
        'task_id': task_id,
        'task_name': task_name,
        'duration': duration,
        'actual_duration': end_time - start_time,
        'thread_name': threading.current_thread().name,
        'status': 'completed',
        'timestamp': time.time()
    }

    # æ›´æ–°ç»Ÿè®¡æ•°æ®
    with stats_lock:
        task_statistics['total_completed'] += 1
        task_statistics['task_results'].append(result)

    print(f"[{threading.current_thread().name}] ä»»åŠ¡ {task_id} ({task_name}) æ‰§è¡Œå®Œæˆ")
    return result


def submit_task_with_tracking(func, args, kwargs, resource_requirements, tags, name, preferred_cluster=None):
    """å¸¦è·Ÿè¸ªçš„æäº¤ä»»åŠ¡å‡½æ•°"""
    try:
        task_id, result = submit_task(
            func=func,
            args=args,
            kwargs=kwargs,
            resource_requirements=resource_requirements,
            tags=tags,
            name=name,
            preferred_cluster=preferred_cluster
        )

        # æ›´æ–°ç»Ÿè®¡æ•°æ®
        with stats_lock:
            task_statistics['total_submitted'] += 1
            if preferred_cluster:
                task_statistics['cluster_distribution'][preferred_cluster] += 1
            else:
                # å¯¹äºæœªæŒ‡å®šé›†ç¾¤çš„ä»»åŠ¡ï¼Œæˆ‘ä»¬åœ¨ç»“æœä¸­è®°å½•å®é™…è°ƒåº¦çš„é›†ç¾¤
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œæ ‡è®°ä¸º"è´Ÿè½½å‡è¡¡"
                task_statistics['cluster_distribution']['load_balanced'] += 1

        return task_id, result
    except Exception as e:
        with stats_lock:
            task_statistics['errors'].append({
                'task_name': name,
                'error': str(e),
                'timestamp': time.time()
            })
        raise


def comprehensive_cross_cluster_test():
    """ç»¼åˆè·¨é›†ç¾¤è°ƒåº¦æµ‹è¯•"""
    print("=" * 80)
    print("ç»¼åˆè·¨é›†ç¾¤è°ƒåº¦æµ‹è¯•")
    print("=" * 80)

    try:
        # 1. åˆå§‹åŒ–è°ƒåº¦å™¨ç¯å¢ƒ
        print("1. åˆå§‹åŒ–è°ƒåº¦å™¨ç¯å¢ƒ...")
        task_lifecycle_manager = initialize_scheduler_environment()
        print("âœ… è°ƒåº¦å™¨ç¯å¢ƒåˆå§‹åŒ–æˆåŠŸ")

        # 2. æ˜¾ç¤ºåˆå§‹é›†ç¾¤ä¿¡æ¯
        print("\n2. åˆå§‹é›†ç¾¤ä¿¡æ¯:")
        cluster_monitor = task_lifecycle_manager.cluster_monitor
        cluster_monitor.refresh_resource_snapshots(force=True)
        cluster_info = cluster_monitor.get_all_cluster_info()

        cluster_resources = {}
        total_capacity = 0
        for name, info in cluster_info.items():
            metadata = info['metadata']
            snapshot = info['snapshot']
            print(f"  é›†ç¾¤ [{name}]:")
            print(f"    åœ°å€: {metadata.head_address}")
            print(f"    æ˜¯å¦åå¥½é›†ç¾¤: {'æ˜¯' if metadata.prefer else 'å¦'}")
            if snapshot:
                cpu_free = snapshot.available_resources.get("CPU", 0)
                cpu_total = snapshot.total_resources.get("CPU", 0)
                gpu_free = snapshot.available_resources.get("GPU", 0)
                gpu_total = snapshot.total_resources.get("GPU", 0)

                cpu_utilization = (cpu_total - cpu_free) / cpu_total if cpu_total > 0 else 0
                gpu_utilization = (gpu_total - gpu_free) / gpu_total if gpu_total > 0 else 0

                cluster_resources[name] = {
                    'cpu_total': cpu_total,
                    'cpu_free': cpu_free,
                    'gpu_total': gpu_total,
                    'gpu_free': gpu_free
                }

                total_capacity += cpu_total

                print(f"    CPU: {cpu_free}/{cpu_total} (ä½¿ç”¨ç‡: {cpu_utilization:.1%})")
                print(f"    GPU: {gpu_free}/{gpu_total} (ä½¿ç”¨ç‡: {gpu_utilization:.1%})")
            else:
                print("    âŒ æ— æ³•è·å–èµ„æºä¿¡æ¯")

        print(f"\n  æ€»é›†ç¾¤CPUå®¹é‡: {total_capacity}")

        # 3. æäº¤å¤§é‡å¹¶å‘ä»»åŠ¡æ¥æµ‹è¯•è´Ÿè½½åˆ†é…
        print(f"\n3. æäº¤ {int(total_capacity) + 10} ä¸ªå¹¶å‘ä»»åŠ¡æ¥æµ‹è¯•è´Ÿè½½åˆ†é…...")

        tasks_to_submit = int(total_capacity) + 10
        submitted_tasks = []

        # æäº¤ä»»åŠ¡åˆ°æŒ‡å®šé›†ç¾¤
        centos_tasks = min(8, tasks_to_submit // 2)
        mac_tasks = min(5, tasks_to_submit // 3)
        balanced_tasks = tasks_to_submit - centos_tasks - mac_tasks

        print(f"  - æäº¤ {centos_tasks} ä¸ªä»»åŠ¡åˆ°centosé›†ç¾¤")
        print(f"  - æäº¤ {mac_tasks} ä¸ªä»»åŠ¡åˆ°macé›†ç¾¤")
        print(f"  - æäº¤ {balanced_tasks} ä¸ªä»»åŠ¡ä½¿ç”¨è´Ÿè½½å‡è¡¡")

        # æäº¤åˆ°centosé›†ç¾¤çš„ä»»åŠ¡
        for i in range(centos_tasks):
            try:
                task_id, result = submit_task_with_tracking(
                    func=test_task_with_stats,
                    args=(f"centos-task-{i}", f"CentOSä»»åŠ¡{i}", 1),
                    kwargs={},
                    resource_requirements={"CPU": 1.0},
                    tags=["test", "centos"],
                    name=f"centos_test_task_{i}",
                    preferred_cluster="centos"
                )
                submitted_tasks.append((task_id, result, "centos"))
                print(f"    âœ… CentOSä»»åŠ¡ {i} æäº¤æˆåŠŸ: {task_id}")
            except Exception as e:
                print(f"    âŒ CentOSä»»åŠ¡ {i} æäº¤å¤±è´¥: {e}")

        # æäº¤åˆ°macé›†ç¾¤çš„ä»»åŠ¡
        for i in range(mac_tasks):
            try:
                task_id, result = submit_task_with_tracking(
                    func=test_task_with_stats,
                    args=(f"mac-task-{i}", f"Macä»»åŠ¡{i}", 1),
                    kwargs={},
                    resource_requirements={"CPU": 1.0},
                    tags=["test", "mac"],
                    name=f"mac_test_task_{i}",
                    preferred_cluster="mac"
                )
                submitted_tasks.append((task_id, result, "mac"))
                print(f"    âœ… Macä»»åŠ¡ {i} æäº¤æˆåŠŸ: {task_id}")
            except Exception as e:
                print(f"    âŒ Macä»»åŠ¡ {i} æäº¤å¤±è´¥: {e}")

        # æäº¤è´Ÿè½½å‡è¡¡ä»»åŠ¡
        for i in range(balanced_tasks):
            try:
                task_id, result = submit_task_with_tracking(
                    func=test_task_with_stats,
                    args=(f"balanced-task-{i}", f"è´Ÿè½½å‡è¡¡ä»»åŠ¡{i}", 1),
                    kwargs={},
                    resource_requirements={"CPU": 1.0},
                    tags=["test", "balanced"],
                    name=f"balanced_test_task_{i}"
                    # ä¸æŒ‡å®špreferred_clusterï¼Œä½¿ç”¨è´Ÿè½½å‡è¡¡
                )
                submitted_tasks.append((task_id, result, "load_balanced"))
                print(f"    âœ… è´Ÿè½½å‡è¡¡ä»»åŠ¡ {i} æäº¤æˆåŠŸ: {task_id}")
            except Exception as e:
                print(f"    âŒ è´Ÿè½½å‡è¡¡ä»»åŠ¡ {i} æäº¤å¤±è´¥: {e}")

        # 4. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        print(f"\n4. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ...")
        time.sleep(15)  # ç­‰å¾…ä»»åŠ¡æ‰§è¡Œå®Œæˆ

        # 5. æ¸…ç†èµ„æº
        print("\n5. æ¸…ç†èµ„æº...")
        if task_lifecycle_manager:
            task_lifecycle_manager.stop()
            print("âœ… ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨å·²åœæ­¢")

        # 6. ç”Ÿæˆç»Ÿè®¡æ•°æ®æŠ¥å‘Š
        print("\n6. ç”Ÿæˆç»Ÿè®¡æ•°æ®æŠ¥å‘Š...")
        generate_statistics_report()

        print("\nğŸ‰ ç»¼åˆè·¨é›†ç¾¤è°ƒåº¦æµ‹è¯•å®Œæˆ!")
        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

        # å°è¯•æ¸…ç†èµ„æº
        try:
            from ray_multicluster_scheduler.app.client_api.submit_task import _task_lifecycle_manager
            if _task_lifecycle_manager:
                _task_lifecycle_manager.stop()
                print("âœ… ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨å·²åœæ­¢")
        except:
            pass

        return False


def generate_statistics_report():
    """ç”Ÿæˆç»Ÿè®¡æ•°æ®æŠ¥å‘Š"""
    print("\n" + "=" * 80)
    print("ğŸ“Š è·¨é›†ç¾¤è°ƒåº¦ç»Ÿè®¡æ•°æ®æŠ¥å‘Š")
    print("=" * 80)

    # æ€»ä½“ç»Ÿè®¡
    print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
    print(f"  æ€»æäº¤ä»»åŠ¡æ•°: {task_statistics['total_submitted']}")
    print(f"  æ€»å®Œæˆä»»åŠ¡æ•°: {task_statistics['total_completed']}")
    print(f"  æˆåŠŸç‡: {task_statistics['total_completed']/task_statistics['total_submitted']*100:.1f}%" if task_statistics['total_submitted'] > 0 else "  æˆåŠŸç‡: 0%")
    print(f"  é”™è¯¯ä»»åŠ¡æ•°: {len(task_statistics['errors'])}")

    # é›†ç¾¤åˆ†å¸ƒç»Ÿè®¡
    print(f"\nğŸ—ºï¸  é›†ç¾¤åˆ†å¸ƒç»Ÿè®¡:")
    for cluster, count in task_statistics['cluster_distribution'].items():
        print(f"  {cluster}: {count} ä¸ªä»»åŠ¡")

    # ä»»åŠ¡æ‰§è¡Œæ—¶é—´ç»Ÿè®¡
    if task_statistics['task_results']:
        durations = [result['actual_duration'] for result in task_statistics['task_results']]
        avg_duration = sum(durations) / len(durations)
        min_duration = min(durations)
        max_duration = max(durations)

        print(f"\nâ±ï¸  ä»»åŠ¡æ‰§è¡Œæ—¶é—´ç»Ÿè®¡:")
        print(f"  å¹³å‡æ‰§è¡Œæ—¶é—´: {avg_duration:.2f} ç§’")
        print(f"  æœ€çŸ­æ‰§è¡Œæ—¶é—´: {min_duration:.2f} ç§’")
        print(f"  æœ€é•¿æ‰§è¡Œæ—¶é—´: {max_duration:.2f} ç§’")

    # é”™è¯¯ç»Ÿè®¡
    if task_statistics['errors']:
        print(f"\nâŒ é”™è¯¯ç»Ÿè®¡:")
        for error in task_statistics['errors']:
            print(f"  ä»»åŠ¡ {error['task_name']}: {error['error']}")

    # é›†ç¾¤è´Ÿè½½åˆ†æ
    print(f"\nğŸ” é›†ç¾¤è´Ÿè½½åˆ†æ:")
    total_tasks = sum(task_statistics['cluster_distribution'].values())
    if total_tasks > 0:
        for cluster, count in task_statistics['cluster_distribution'].items():
            percentage = (count / total_tasks) * 100
            print(f"  {cluster}: {count} ä¸ªä»»åŠ¡ ({percentage:.1f}%)")


def demonstrate_cross_cluster_scheduling_behavior():
    """æ¼”ç¤ºè·¨é›†ç¾¤è°ƒåº¦è¡Œä¸º"""
    print("\n" + "=" * 80)
    print("ğŸš€ è·¨é›†ç¾¤è°ƒåº¦è¡Œä¸ºæ¼”ç¤º")
    print("=" * 80)

    print("\nç³»ç»Ÿè·¨é›†ç¾¤è°ƒåº¦æœºåˆ¶è¯´æ˜:")
    print("1. é¦–é€‰é›†ç¾¤ä¼˜å…ˆ: å¦‚æœç”¨æˆ·æŒ‡å®šäº†preferred_clusterï¼Œç³»ç»Ÿä¼šä¼˜å…ˆå°è¯•è°ƒåº¦åˆ°è¯¥é›†ç¾¤")
    print("2. èµ„æºé˜ˆå€¼æ§åˆ¶: å½“é›†ç¾¤èµ„æºä½¿ç”¨ç‡è¶…è¿‡80%æ—¶ï¼Œæ–°ä»»åŠ¡ä¼šè¢«æ”¾å…¥é˜Ÿåˆ—ç­‰å¾…")
    print("3. è´Ÿè½½å‡è¡¡: æœªæŒ‡å®šé¦–é€‰é›†ç¾¤æ—¶ï¼Œç³»ç»Ÿä¼šé€‰æ‹©èµ„æºæœ€å……è¶³çš„é›†ç¾¤")
    print("4. åŠ¨æ€é‡è°ƒåº¦: ç³»ç»Ÿæ¯30ç§’ä¼šé‡æ–°è¯„ä¼°é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ï¼Œå°è¯•å°†å…¶è°ƒåº¦åˆ°åˆé€‚çš„é›†ç¾¤")
    print("5. ä»»åŠ¡é˜Ÿåˆ—: æ— æ³•ç«‹å³è°ƒåº¦çš„ä»»åŠ¡ä¼šè¢«ä¿å­˜åœ¨é˜Ÿåˆ—ä¸­ï¼Œç›´åˆ°æœ‰åˆé€‚èµ„æº")

    print("\næµ‹è¯•åœºæ™¯æ€»ç»“:")
    print("âœ“ ç³»ç»Ÿèƒ½å¤Ÿæ ¹æ®é›†ç¾¤èµ„æºæƒ…å†µæ™ºèƒ½è°ƒåº¦ä»»åŠ¡")
    print("âœ“ æŒ‡å®šé›†ç¾¤çš„ä»»åŠ¡ä¼šä¼˜å…ˆè°ƒåº¦åˆ°æŒ‡å®šé›†ç¾¤")
    print("âœ“ æœªæŒ‡å®šé›†ç¾¤çš„ä»»åŠ¡ä¼šæ ¹æ®è´Ÿè½½å‡è¡¡ç®—æ³•è°ƒåº¦")
    print("âœ“ èµ„æºç´§å¼ æ—¶ä»»åŠ¡ä¼šè¿›å…¥é˜Ÿåˆ—ç­‰å¾…")
    print("âœ“ èµ„æºé‡Šæ”¾åé˜Ÿåˆ—ä¸­çš„ä»»åŠ¡ä¼šè¢«é‡æ–°è°ƒåº¦")


if __name__ == "__main__":
    # è¿è¡Œç»¼åˆè·¨é›†ç¾¤è°ƒåº¦æµ‹è¯•
    success = comprehensive_cross_cluster_test()

    # æ¼”ç¤ºè·¨é›†ç¾¤è°ƒåº¦è¡Œä¸º
    demonstrate_cross_cluster_scheduling_behavior()

    print("\n" + "=" * 80)
    if success:
        print("ğŸ‰ ç»¼åˆè·¨é›†ç¾¤è°ƒåº¦æµ‹è¯•é€šè¿‡!")
    else:
        print("âš ï¸  ç»¼åˆè·¨é›†ç¾¤è°ƒåº¦æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
    print("=" * 80)